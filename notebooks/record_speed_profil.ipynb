{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28afba8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "timeseries_folder=\"../data/timeseries\"\n",
    "# name = \"16285738312.csv\" # seuil 5x5'\n",
    "name = \"16262137158.csv\" # sl 2 alpes\n",
    "name = \"16251238864.csv\" # cÃ´te rapide pisse\n",
    "name = \"16235724470.csv\" # VMA\n",
    "name = \"16285738312.csv\" # seuil 5x5'\n",
    "\n",
    "\n",
    "df = pd.read_csv(os.path.join(timeseries_folder, name))\n",
    "\n",
    "df.head()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8df0840",
   "metadata": {},
   "outputs": [],
   "source": [
    "from haversine import haversine\n",
    "import numpy as np\n",
    "def distance(df, lat_col=\"lat\", lon_col=\"lon\"):\n",
    "    \"\"\"\n",
    "    Compute the distance between 2 consecutives row based on the latitude and longitude for all the rows.\n",
    "    Create a new column with the distance.\n",
    "    \"\"\"\n",
    "    # Compute pairwise distances row-by-row\n",
    "    df['distance'] = [\n",
    "        haversine((lat1, lon1), (lat2, lon2))\n",
    "        for lat1, lon1, lat2, lon2 in zip(\n",
    "            df[lat_col].shift(),\n",
    "            df[lon_col].shift(),\n",
    "            df[lat_col],\n",
    "            df[lon_col]\n",
    "        )\n",
    "    ]\n",
    "    # df['distance'] = df['distance'].fillna(0)\n",
    "    return df\n",
    "\n",
    "def cumulated_distance(df, distance_col=\"distance\"):\n",
    "    \"\"\"\n",
    "    Compute the cumulated distance of the dataframe based on the distance column.\n",
    "    Create a new column with the cumulated distance.\n",
    "    \"\"\"\n",
    "    df['cumulated_distance'] = df[distance_col].cumsum()\n",
    "    return df\n",
    "def time_from_timestamp(df, timestamp_col=\"timestamp\"):\n",
    "    \"\"\"\n",
    "    Convert the timestamp column to a datetime object.\n",
    "    \"\"\"\n",
    "    df[timestamp_col] = pd.to_datetime(df[timestamp_col])\n",
    "    df['time'] = df[timestamp_col].dt.time\n",
    "    return df\n",
    "def duration(df, timestamp_col=\"timestamp\"):\n",
    "    \"\"\"\n",
    "    Compute the duration of the dataframe based on the timestamp column.\n",
    "    Create a new column with the duration.\n",
    "    \"\"\"\n",
    "    df['duration'] = df[timestamp_col].diff().fillna(pd.Timedelta(seconds=0))\n",
    "    df['cumulated_duration'] = df['duration'].cumsum()\n",
    "    df['duration_seconds'] = df['duration'].dt.total_seconds()\n",
    "    df['cumulated_duration_seconds'] = df['duration_seconds'].cumsum()\n",
    "    # df = df.drop(columns=['duration'])\n",
    "    return df\n",
    "\n",
    "def speed(df, distance_col=\"distance\", time_col=\"duration_seconds\"):\n",
    "    \"\"\"\n",
    "    Compute the speed of the dataframe based on the distance and time columns.\n",
    "    Create a new column with the speed.\n",
    "    \"\"\"\n",
    "    print(\"Nan or 0 values in time_col: \", df[time_col].isna().sum(), (df[time_col] == 0).sum())\n",
    "\n",
    "    # Replace 0 values in time_col with the mean of non-zero values\n",
    "    mean_time = df.loc[df[time_col] > 0, time_col].mean().round(1)\n",
    "    print(\"Setting 0 values in time_col to the mean of non-zero values: \", mean_time)\n",
    "    df[time_col] = df[time_col].replace(0, mean_time)\n",
    "    df['speed_m_s'] = 1000*df[distance_col] / df[time_col]\n",
    "    df['speed_km_h'] = 3.6*df['speed_m_s']\n",
    "\n",
    "    return df\n",
    "\n",
    "def elevation(df, elevation_col=\"elevationM\"):\n",
    "    \"\"\"\n",
    "    Compute the elevation difference of the dataframe based on the elevation column.\n",
    "    Create a new column with the elevation difference.\n",
    "    \"\"\"\n",
    "    df['elevation_difference'] = df[elevation_col].diff().fillna(0)\n",
    "    df['elevation_cumulated'] = df['elevation_difference'].cumsum()\n",
    "    df['elevation_gain'] = df['elevation_difference'].apply(lambda x: x if x > 0 else 0).cumsum()\n",
    "    df['elevation_loss'] = df['elevation_difference'].apply(lambda x: -x if x < 0 else 0).cumsum()\n",
    "    return df\n",
    "\n",
    "def grade(df, distance_col=\"distance\", elevation_col=\"elevation_difference\"):\n",
    "    \"\"\"\n",
    "    Compute the grade of the dataframe based on the distance and elevation columns.\n",
    "    Create a new column with the grade.\n",
    "    \"\"\"\n",
    "    df['grade'] = df[elevation_col] / df[distance_col]*1000\n",
    "    df['grade'] = df['grade'].replace(np.inf, 0)\n",
    "    df['grade'] = df['grade'].replace(-np.inf, 0)\n",
    "\n",
    "    df['grade'] = df['grade'].replace(np.nan, 0)\n",
    "    df['grade'] = df['grade'].fillna(0)\n",
    "\n",
    "    return df\n",
    "def moving_average(df, window_size=5, col=\"distance\"):\n",
    "    \"\"\"\n",
    "    Compute the moving average of the distance column over a specified window size.\n",
    "    Create a new column with the moving average distance.\n",
    "    \"\"\"\n",
    "    df[f'{col}_ma_{window_size}'] = df[col].rolling(window=window_size,min_periods=1, center=True).mean()\n",
    "    return df\n",
    "\n",
    "def hist(df, col=\"grade\"):\n",
    "# Compute histogram as a table\n",
    "    hist, bins = pd.cut(df[col], bins=10, retbins=True)\n",
    "    hist_table = hist.value_counts().sort_index().reset_index()\n",
    "    hist_table.columns = [f\"{col}_Bin\", \"Frequency\"]\n",
    "    return hist_table\n",
    "\n",
    "\n",
    "# ids =[9033,9034,9035,9036,9037]\n",
    "# for id_val in ids:\n",
    "#     print(f\"Processing ID: {id_val}\")\n",
    "#     print(df.iloc[id_val])\n",
    "\n",
    "\n",
    "df = moving_average(df, window_size=5, col=\"lat\")\n",
    "df = moving_average(df, window_size=5, col=\"lon\")\n",
    "df = distance(df, lat_col=\"lat_ma_5\", lon_col=\"lon_ma_5\")\n",
    "# Get rows where distance is 0\n",
    "df = elevation(df)\n",
    "\n",
    "\n",
    "print(\"Number of rows before filtering: \", len(df))\n",
    "print(\"Percentage of rows removed: \", (len(df) - len(df[df['distance'] > 1e-5])) / len(df) * 100,\" %\")\n",
    "df =df[df['distance'] > 1e-5].reset_index(drop=True)\n",
    "print(\"Number of rows after filtering: \", len(df))\n",
    "df['distance'] = df['distance'].interpolate(method='linear')\n",
    "\n",
    "df = time_from_timestamp(df)\n",
    "df = duration(df)\n",
    "# Get value counts of duration_seconds\n",
    "duration_counts = df['duration_seconds'].value_counts().sort_index()\n",
    "print(\"Value counts of duration_seconds:\")\n",
    "print(duration_counts)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df = cumulated_distance(df)\n",
    "df = moving_average(df, window_size=30, col=\"distance\")\n",
    "df = speed(df, distance_col=\"distance\", time_col=\"duration_seconds\")\n",
    "\n",
    "# Get rows where speed < 40\n",
    "df = df[df['speed_km_h'] < 40]\n",
    "\n",
    "\n",
    "\n",
    "df = grade(df, distance_col=\"distance_ma_30\", elevation_col=\"elevation_difference\")\n",
    "print(df.head(-5))\n",
    "\n",
    "hist_table = hist(df, col=\"duration_seconds\")\n",
    "# Display the histogram table\n",
    "print(hist_table)\n",
    "\n",
    "\n",
    "# Compare paceKmh vs speed_km_h\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe27fad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df['paceKmh'], df['speed_km_h'], alpha=0.5)\n",
    "plt.xlabel('paceKmh')\n",
    "plt.ylabel('speed_km_h')\n",
    "plt.title('Comparison of paceKmh vs speed_km_h')\n",
    "plt.grid(True)\n",
    "\n",
    "# Add a diagonal line for reference (y = x)\n",
    "min_val = min(df['paceKmh'].min(), df['speed_km_h'].min())\n",
    "max_val = max(df['paceKmh'].max(), df['speed_km_h'].max())\n",
    "plt.plot([min_val, max_val], [min_val, max_val], 'r--', alpha=0.7, label='y = x')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Compute correlation\n",
    "print(df[['paceKmh','speed_km_h']].describe())\n",
    "correlation = df['paceKmh'].corr(df['speed_km_h'])\n",
    "print(f\"Correlation between paceKmh and speed_km_h: {correlation:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cb68f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot paceKmh and speed_km_h over time for comparison\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(df['cumulated_duration_seconds'], df['paceKmh'], label='paceKmh', alpha=0.7)\n",
    "plt.plot(df['cumulated_duration_seconds'], df['speed_km_h'], label='speed_km_h', alpha=0.7)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Speed (km/h)')\n",
    "plt.title('Comparison of paceKmh and speed_km_h over Time')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4552e1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute correlation between speed_km_h and hr with offset optimization\n",
    "\n",
    "df = df[df['hr'] > 120].copy()\n",
    "\n",
    "df = moving_average(df, window_size=10, col=\"hr\")\n",
    "df = moving_average(df, window_size=10, col=\"speed_km_h\")\n",
    "#rename the columns\n",
    "df.rename(columns={\"hr_ma_10\":\"hr_smooth\", \"speed_km_h_ma_10\":\"speed_smooth\"}, inplace=True)\n",
    "hr_col=\"hr_smooth\"\n",
    "col=\"speed_smooth\"\n",
    "\n",
    "# CORRELATION COMPUTATION: Find best offset for correlation\n",
    "best_correlation = 0\n",
    "best_offset = 0\n",
    "correlations = []\n",
    "\n",
    "for offset in range(-60, 60):\n",
    "    # Shift heart rate data by offset\n",
    "    shifted_hr = df[hr_col].shift(offset)\n",
    "    # CORRELATION COMPUTATION: Calculate correlation with non-null values only using pd.corr\n",
    "    valid_data = pd.concat([df[col], shifted_hr], axis=1).dropna()\n",
    "    if len(valid_data) > 0:\n",
    "        correlation = valid_data.corr().iloc[0, 1]\n",
    "        correlations.append((offset, correlation))\n",
    "        if abs(correlation) > abs(best_correlation):\n",
    "            best_correlation = correlation\n",
    "            best_offset = offset\n",
    "    else:\n",
    "        print(f\"No valid data for offset {offset}\")\n",
    "\n",
    "print(f\"Best correlation: {best_correlation:.4f} at offset: {best_offset}\")\n",
    "\n",
    "# CORRELATION COMPUTATION: Calculate original correlation safely using pd.corr\n",
    "original_corr_data = pd.concat([df[col], df[hr_col]], axis=1).dropna()\n",
    "if len(original_corr_data) > 0:\n",
    "    original_correlation = original_corr_data.corr().iloc[0, 1]\n",
    "    print(f\"Original correlation: {original_correlation:.4f}\")\n",
    "else:\n",
    "    print(\"Original correlation: No valid data for correlation calculation\")\n",
    "\n",
    "# Apply best offset\n",
    "df['hr_shifted'] = df[hr_col].shift(best_offset)\n",
    "\n",
    "# Scatter plot with best offset\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df['hr_shifted'], df[col], alpha=0.5)\n",
    "plt.xlabel(f'Heart Rate (bpm) shifted by {best_offset}')\n",
    "plt.ylabel('Speed (km/h)')\n",
    "plt.title(f'Speed vs Heart Rate (Best offset: {best_offset}, Correlation: {best_correlation:.4f})')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot hr (with best offset) and speed_km_h over time for comparison with dual y-axes\n",
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Plot shifted heart rate on left y-axis\n",
    "ax1.plot(df['cumulated_duration_seconds'], df['hr_shifted'], label=f'Heart Rate (shifted by {best_offset})', alpha=0.7, color='orange')\n",
    "ax1.set_xlabel('Time')\n",
    "ax1.set_ylabel(f'Heart Rate (bpm) shifted by {best_offset}', color='orange')\n",
    "ax1.tick_params(axis='y', labelcolor='orange')\n",
    "ax1.grid(True)\n",
    "\n",
    "# Create second y-axis for speed\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(df['cumulated_duration_seconds'], df[col], label='Speed (km/h)', alpha=0.7, color='blue')\n",
    "ax2.set_ylabel('Speed (km/h)', color='blue')\n",
    "ax2.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "# Combine legends from both axes\n",
    "lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax1.legend(lines1 + lines2, labels1 + labels2, loc='best')\n",
    "\n",
    "plt.title(f'Heart Rate (shifted by {best_offset}) and Speed over Time\\nCorrelation: {best_correlation:.4f}')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f70ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute clusters in the hr, speed space using KMeans\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "elbow=False\n",
    "hr_col=\"hr_shifted\"\n",
    "X = df[[hr_col, col]].dropna()\n",
    "if elbow:\n",
    "    # Use elbow method to determine optimal number of clusters\n",
    "    wcss = []\n",
    "    for i in range(1, 11):\n",
    "        kmeans = KMeans(n_clusters=i, random_state=42, n_init=10)\n",
    "        kmeans.fit(X)\n",
    "        wcss.append(kmeans.inertia_)\n",
    "\n",
    "    # Plot elbow method\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, 11), wcss, marker='o')\n",
    "    plt.xlabel('Number of Clusters')\n",
    "    plt.ylabel('WCSS')\n",
    "    plt.title('Elbow Method for Optimal Clusters')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Based on elbow method, choose optimal number of clusters (typically 2-3 for this type of data)\n",
    "n_clusters = 7\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "clusters = kmeans.fit_predict(X)\n",
    "\n",
    "# Add cluster labels to the dataframe\n",
    "df_clustered = X.copy()\n",
    "df_clustered['cluster'] = clusters\n",
    "\n",
    "# Plot clustered data\n",
    "plt.figure(figsize=(10, 6))\n",
    "scatter = plt.scatter(df_clustered[hr_col], df_clustered[col], \n",
    "                     c=df_clustered['cluster'], cmap='viridis', alpha=0.7)\n",
    "plt.colorbar(scatter, label='Cluster')\n",
    "plt.xlabel('Heart Rate (bpm)')\n",
    "plt.ylabel('Speed (km/h)')\n",
    "plt.title(f'Clustering in HR-Speed Space (K={n_clusters})')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Print cluster statistics\n",
    "print(f\"\\nCluster Statistics (K={n_clusters}):\")\n",
    "for cluster_id in range(n_clusters):\n",
    "    cluster_data = df_clustered[df_clustered['cluster'] == cluster_id]\n",
    "    print(f\"Cluster {cluster_id}:\")\n",
    "    print(f\"  Size: {len(cluster_data)} points\")\n",
    "    print(f\"  Mean HR: {cluster_data[hr_col].mean():.1f} bpm\")\n",
    "    print(f\"  Mean Speed: {cluster_data[col].mean():.1f} km/h\")\n",
    "    print(f\"  HR Range: {cluster_data[hr_col].min():.1f} - {cluster_data[hr_col].max():.1f} bpm\")\n",
    "    print(f\"  Speed Range: {cluster_data[col].min():.1f} - {cluster_data[col].max():.1f} km/h\")\n",
    "    print(f\"  Std HR: {cluster_data[hr_col].std():.1f} bpm\")\n",
    "    print(f\"  Std Speed: {cluster_data[col].std():.1f} km/h\")\n",
    "    print()\n",
    "\n",
    "# Add cluster information to original dataframe for time series plotting\n",
    "df_with_clusters = df.copy()\n",
    "df_with_clusters['cluster'] = df_with_clusters.index.map(lambda idx: clusters[df_with_clusters.index.get_indexer([idx])[0]] \n",
    "                                                         if idx in X.index else -1)\n",
    "\n",
    "# Plot hr and speed_km_h over time with cluster coloring using dual y-axes\n",
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Plot heart rate on left y-axis with cluster coloring\n",
    "scatter1 = ax1.scatter(df_with_clusters['cumulated_duration_seconds'], df_with_clusters[\"hr_smooth\"], \n",
    "                      c=df_with_clusters['cluster'], cmap='viridis', alpha=0.7, s=20)\n",
    "ax1.set_xlabel('Time (seconds)')\n",
    "ax1.set_ylabel('Heart Rate (bpm)', color='orange')\n",
    "ax1.tick_params(axis='y', labelcolor='orange')\n",
    "ax1.grid(True)\n",
    "\n",
    "# Create second y-axis for speed\n",
    "ax2 = ax1.twinx()\n",
    "scatter2 = ax2.scatter(df_with_clusters['cumulated_duration_seconds'], df_with_clusters[col], \n",
    "                      c=df_with_clusters['cluster'], cmap='viridis', alpha=0.7, s=20)\n",
    "ax2.set_ylabel('Speed (km/h)', color='blue')\n",
    "ax2.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "# Add colorbar for clusters\n",
    "cbar = plt.colorbar(scatter1, ax=[ax1, ax2])\n",
    "cbar.set_label('Cluster')\n",
    "\n",
    "plt.title('Heart Rate and Speed over Time with Cluster Coloring')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a79c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "from scipy import stats as scipy_stats\n",
    "import itertools\n",
    "\n",
    "# Get cluster centers\n",
    "cluster_centers = kmeans.cluster_centers_\n",
    "\n",
    "# Calculate cluster standard deviations for mustaches\n",
    "cluster_hr_stds = []\n",
    "cluster_speed_stds = []\n",
    "for cluster_id in range(n_clusters):\n",
    "    cluster_data = df_clustered[df_clustered['cluster'] == cluster_id]\n",
    "    cluster_hr_stds.append(cluster_data[hr_col].std())\n",
    "    cluster_speed_stds.append(cluster_data[col].std())\n",
    "\n",
    "# lin reg with all clusters\n",
    "slope, intercept, original_r_value, p_value, std_err = stats.linregress(cluster_centers[:, 0], cluster_centers[:, 1])\n",
    "# Plot original cluster centers and linear regression\n",
    "plt.figure(figsize=(10, 6))\n",
    "scatter = plt.scatter(cluster_centers[:, 0], cluster_centers[:, 1], \n",
    "                     c=np.arange(len(cluster_centers)), cmap='viridis', s=200, alpha=0.8)\n",
    "plt.colorbar(scatter, label='Cluster ID')\n",
    "plt.xlabel('Heart Rate (bpm)')\n",
    "plt.ylabel('Speed (km/h)')\n",
    "\n",
    "# Add mustaches for cluster centers based on cluster std\n",
    "for i, center in enumerate(cluster_centers):\n",
    "    hr_std = cluster_hr_stds[i]\n",
    "    speed_std = cluster_speed_stds[i]\n",
    "    plt.errorbar(center[0], center[1], \n",
    "                xerr=hr_std, yerr=speed_std,\n",
    "                fmt='none', ecolor='gray', alpha=0.6, capsize=3, capthick=1)\n",
    "\n",
    "# Plot linear regression line with std mustache\n",
    "x_range = np.linspace(cluster_centers[:, 0].min(), cluster_centers[:, 0].max(), 100)\n",
    "y_pred = slope * x_range + intercept\n",
    "plt.plot(x_range, y_pred, 'r-', linewidth=2, \n",
    "label=f'Linear fit (RÂ² = {original_r_value**2:.3f}) Formula: y = {slope:.2f}x + {intercept:.2f}')\n",
    "\n",
    "# Add std mustache (confidence interval)\n",
    "y_upper = y_pred + std_err\n",
    "y_lower = y_pred - std_err\n",
    "plt.fill_between(x_range, y_lower, y_upper, color='red', alpha=0.2, label=f'Â±1 std error ({std_err:.2f})')\n",
    "\n",
    "plt.title(f'Original Cluster Centers (RÂ² = {original_r_value**2:.3f})')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Only perform cluster removal if original R value is lower than threshold (0.9)\n",
    "if original_r_value < 0.95 and len(cluster_centers) > 1:\n",
    "    n_centers = len(cluster_centers)\n",
    "    remove_count = max(1, int(n_centers * 0.2))  # Remove approximately 20% of clusters\n",
    "    \n",
    "    best_r_squared = -1\n",
    "    best_combination = None\n",
    "    best_filtered_centers = None\n",
    "    \n",
    "    # Generate all combinations of clusters to remove\n",
    "    for clusters_to_remove in itertools.combinations(range(n_centers), remove_count):\n",
    "        keep_mask = np.ones(n_centers, dtype=bool)\n",
    "        keep_mask[list(clusters_to_remove)] = False\n",
    "        \n",
    "        current_centers = cluster_centers[keep_mask]\n",
    "        x_centers = current_centers[:, 0]\n",
    "        y_centers = current_centers[:, 1]\n",
    "        \n",
    "        if len(current_centers) > 1:\n",
    "            slope, intercept, r_value, p_value, std_err = stats.linregress(x_centers, y_centers)\n",
    "            current_r_squared = r_value**2\n",
    "            \n",
    "            if current_r_squared > best_r_squared:\n",
    "                best_r_squared = current_r_squared\n",
    "                best_combination = clusters_to_remove\n",
    "                best_filtered_centers = current_centers\n",
    "                best_keep_mask = keep_mask\n",
    "    \n",
    "    if best_filtered_centers is not None:\n",
    "        filtered_centers = best_filtered_centers\n",
    "        filtered_cluster_ids = np.arange(n_clusters)[best_keep_mask]\n",
    "        print(f\"Removed clusters {list[int](best_combination)} to improve RÂ² from {original_r_value**2:.3f} to {best_r_squared:.3f}\")\n",
    "    else:\n",
    "        # Fallback: keep all clusters if no improvement found\n",
    "        filtered_centers = cluster_centers\n",
    "        filtered_cluster_ids = np.arange(n_clusters)\n",
    "else:\n",
    "    # If original R value is >= 0.9 or only one cluster center, keep all clusters\n",
    "    filtered_centers = cluster_centers\n",
    "    filtered_cluster_ids = np.arange(n_clusters)\n",
    "    if len(cluster_centers) > 1 and original_r_value >= 0.9:\n",
    "        print(f\"Original R value ({original_r_value:.3f}) is >= 0.9, keeping all clusters\")\n",
    "\n",
    "# Plot filtered cluster centers\n",
    "plt.figure(figsize=(10, 6))\n",
    "scatter = plt.scatter(filtered_centers[:, 0], filtered_centers[:, 1], \n",
    "                     c=filtered_cluster_ids, cmap='viridis', s=200, alpha=0.8)\n",
    "plt.colorbar(scatter, label='Cluster ID')\n",
    "plt.xlabel('Heart Rate (bpm)')\n",
    "plt.ylabel('Speed (km/h)')\n",
    "plt.title(f'Filtered Cluster Centers (K={n_clusters}, {len(filtered_centers)} after optimal removal)')\n",
    "\n",
    "# Add mustaches for filtered cluster centers based on cluster std\n",
    "for i, center in enumerate(filtered_centers):\n",
    "    cluster_id = filtered_cluster_ids[i]\n",
    "    cluster_data = df_clustered[df_clustered['cluster'] == cluster_id]\n",
    "    hr_std = cluster_data[hr_col].std()\n",
    "    speed_std = cluster_data[col].std()\n",
    "    plt.errorbar(center[0], center[1], \n",
    "                xerr=hr_std, yerr=speed_std,\n",
    "                fmt='none', ecolor='gray', alpha=0.6, capsize=3, capthick=1)\n",
    "\n",
    "# Annotate each filtered cluster center with its coordinates\n",
    "for i, center in enumerate(filtered_centers):\n",
    "    plt.annotate(f'({center[0]:.1f}, {center[1]:.1f})', \n",
    "                (center[0], center[1]), \n",
    "                xytext=(5, 5), \n",
    "                textcoords='offset points',\n",
    "                fontsize=9)\n",
    "\n",
    "# Add linear regression based on filtered cluster centers with std mustache\n",
    "if len(filtered_centers) > 1:\n",
    "    x_centers = filtered_centers[:, 0]\n",
    "    y_centers = filtered_centers[:, 1]\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(x_centers, y_centers)\n",
    "    x_range = np.linspace(min(x_centers), max(x_centers), 100)\n",
    "    y_pred = slope * x_range + intercept\n",
    "    plt.plot(x_range, y_pred, 'r--', linewidth=2, \n",
    "             label=f'Linear Fit: y = {slope:.2f}x + {intercept:.2f}\\nRÂ² = {r_value**2:.3f}')\n",
    "    \n",
    "    # Add std mustache (confidence interval)\n",
    "    y_upper = y_pred + std_err\n",
    "    y_lower = y_pred - std_err\n",
    "    plt.fill_between(x_range, y_lower, y_upper, color='red', alpha=0.2, label=f'Â±1 std error ({std_err:.2f})')\n",
    "    \n",
    "    plt.legend()\n",
    "\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print filtered cluster centers\n",
    "print(f\"\\nFiltered Cluster Centers (K={n_clusters}, {len(filtered_centers)} after optimal removal):\")\n",
    "for i, center in enumerate(filtered_centers):\n",
    "    cluster_id = filtered_cluster_ids[i]\n",
    "    print(f\"Cluster {cluster_id}: HR={center[0]:.1f} bpm, Speed={center[1]:.1f} km/h\")\n",
    "\n",
    "hr_list= [140,150,160,170,180,185,190,195,200]\n",
    "for hr in hr_list:\n",
    "    speed = slope * hr + intercept\n",
    "    print(f\"Heart Rate: {hr} bpm, Speed: {speed:.1f} km/h\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72800423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histograms for each cluster\n",
    "fig, axes = plt.subplots(n_clusters, 2, figsize=(12, 4*n_clusters))\n",
    "\n",
    "for cluster_id in range(n_clusters):\n",
    "    cluster_data = df_with_clusters[df_with_clusters['cluster'] == cluster_id]\n",
    "    \n",
    "    # Speed histogram\n",
    "    speed_mean = cluster_data[col].mean()\n",
    "    axes[cluster_id, 0].hist(cluster_data[col], bins=20, alpha=0.7, color='blue')\n",
    "    axes[cluster_id, 0].axvline(speed_mean, color='darkblue', linestyle='--', linewidth=2, label=f'Mean: {speed_mean:.1f} km/h')\n",
    "    axes[cluster_id, 0].set_xlabel('Speed (km/h)')\n",
    "    axes[cluster_id, 0].set_ylabel('Frequency')\n",
    "    axes[cluster_id, 0].set_title(f'Cluster {cluster_id} - Speed Distribution')\n",
    "    axes[cluster_id, 0].grid(True, alpha=0.3)\n",
    "    axes[cluster_id, 0].legend()\n",
    "    \n",
    "    # Heart rate histogram\n",
    "    hr_mean = cluster_data[hr_col].mean()\n",
    "    axes[cluster_id, 1].hist(cluster_data[hr_col], bins=20, alpha=0.7, color='red')\n",
    "    axes[cluster_id, 1].axvline(hr_mean, color='darkred', linestyle='--', linewidth=2, label=f'Mean: {hr_mean:.1f} bpm')\n",
    "    axes[cluster_id, 1].set_xlabel('Heart Rate (bpm)')\n",
    "    axes[cluster_id, 1].set_ylabel('Frequency')\n",
    "    axes[cluster_id, 1].set_title(f'Cluster {cluster_id} - Heart Rate Distribution')\n",
    "    axes[cluster_id, 1].grid(True, alpha=0.3)\n",
    "    axes[cluster_id, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139ca8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute correlation between speed and heart rate for each cluster\n",
    "print(f\"\\nCorrelation between {col} and {hr_col} for each cluster:\")\n",
    "fig, axes = plt.subplots(1, n_clusters, figsize=(4*n_clusters, 4))\n",
    "if n_clusters == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for cluster_id in range(n_clusters):\n",
    "    cluster_data = df_with_clusters[df_with_clusters['cluster'] == cluster_id]\n",
    "    correlation = cluster_data[col].corr(cluster_data[hr_col])\n",
    "    print(f\"Cluster {cluster_id}: Correlation = {correlation:.3f}\")\n",
    "    \n",
    "    # Plot scatter plot for correlation visualization\n",
    "    axes[cluster_id].scatter(cluster_data[col], cluster_data[hr_col], alpha=0.6)\n",
    "    axes[cluster_id].set_xlabel('Speed (km/h)')\n",
    "    axes[cluster_id].set_ylabel('Heart Rate (bpm)')\n",
    "    axes[cluster_id].set_title(f'Cluster {cluster_id}\\nCorrelation: {correlation:.3f}')\n",
    "    axes[cluster_id].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682d788d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute max average speed over different window sizes\n",
    "def compute_profile(df, col,additional_col=None, window_sizes=[5, 10, 15, 20, 30, 60]):\n",
    "    \"\"\"\n",
    "    Compute the speed profile by calculating max average speeds for different window sizes.\n",
    "    \n",
    "    Parameters:\n",
    "    df (DataFrame): The input dataframe containing speed data\n",
    "    speed_col (str): The column name containing speed values\n",
    "    window_sizes (list): List of window sizes in seconds for rolling average\n",
    "    \n",
    "    Returns:\n",
    "    dict: Dictionary with window sizes as keys and max average speeds as values\n",
    "    \"\"\"\n",
    "    max_avg_speeds = {}\n",
    "    max_avg_additional_values = {}\n",
    "    \n",
    "    print(\"Max average speed for different window sizes:\")\n",
    "    for window_size in window_sizes:\n",
    "        # Calculate rolling average speed for the specified window\n",
    "        rolling_avg = df[col].rolling(window=window_size,min_periods=1,center=True).mean()\n",
    "        max_avg = rolling_avg.max()\n",
    "        max_avg_idx = rolling_avg.idxmax()-best_offset\n",
    "        max_avg_speeds[window_size] = max_avg\n",
    "        print(f\"Window size {window_size}s: Max average {col} = {max_avg:.1f}\")\n",
    "        \n",
    "        # If additional_col is provided, calculate and print its values at the same position as max_avg_speed\n",
    "        if additional_col is not None:\n",
    "            # Calculate the average of additional_col over the window_size centered on max_avg_idx\n",
    "            if pd.notna(max_avg_idx):\n",
    "                half_window = window_size // 2\n",
    "                start_idx = max(0, max_avg_idx - half_window)\n",
    "                end_idx = min(len(df), max_avg_idx + half_window + 1)\n",
    "                additional_avg = df.loc[start_idx:end_idx, additional_col].mean()\n",
    "            else:\n",
    "                additional_avg = None\n",
    "            max_avg_additional_values[window_size] = additional_avg\n",
    "            print(f\"Window size {window_size}s: Average {additional_col} around max speed position = {additional_avg:.1f}\")\n",
    "    return max_avg_speeds,max_avg_additional_values\n",
    "window_sizes = [15, 20, 30, 60,120,180,240,300,360,420,480,540,600,660,720,780,840,900,960,1020,\n",
    "                1080,1140,1200,1320,1440,1560,1680,1920,2160,2400,2640,2880,3120,3360,3600]  # window sizes in seconds\n",
    "# Compute the speed profile\n",
    "max_avg_speeds,max_avg_additional_values = compute_profile(df_with_clusters, \"speed_km_h\", \"hr\", window_sizes)\n",
    "\n",
    "# Optional: Plot the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(list(max_avg_speeds.keys()), list(max_avg_speeds.values()), 'o-', linewidth=2, markersize=8)\n",
    "plt.xlabel('Window Size (seconds)')\n",
    "plt.ylabel('Max Average Speed (km/h)')\n",
    "plt.title('Max Average Speed vs Window Size')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xscale('log')\n",
    "plt.xticks(window_sizes, labels=window_sizes)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(list(max_avg_speeds.keys()), list(max_avg_additional_values.values()), 'o-', linewidth=2, markersize=8)\n",
    "plt.xlabel('Window Size (seconds)')\n",
    "plt.ylabel('Max Average Heart Rate (bpm)')\n",
    "plt.title('Max Average Heart Rate vs Window Size')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xscale('log')\n",
    "plt.xticks(window_sizes, labels=window_sizes)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38388145",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compute the heart rate profile\n",
    "max_avg_hrs,_ = compute_profile(df_with_clusters, \"hr\",None, window_sizes)\n",
    "\n",
    "# Optional: Plot the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(list(max_avg_hrs.keys()), list(max_avg_hrs.values()), 'o-', linewidth=2, markersize=8, color='red')\n",
    "plt.xlabel('Window Size (seconds)')\n",
    "plt.ylabel('Max Average Heart Rate (bpm)')\n",
    "plt.title('Max Average Heart Rate vs Window Size')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xscale('log')\n",
    "plt.xticks(window_sizes, labels=window_sizes)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2228c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot max_avg_hr and speed together for comparison\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plot speed profile (x-axis)\n",
    "plt.scatter( list(max_avg_hrs.values())   , list(max_avg_speeds.values()),\n",
    "         linewidth=2, s=80, color='green', label='Speed vs Heart Rate')\n",
    "\n",
    "# Add linear regression\n",
    "y_values = list(max_avg_speeds.values())\n",
    "x_values = list(max_avg_hrs.values())\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(x_values, y_values)\n",
    "regression_line = slope * np.array(x_values) + intercept\n",
    "plt.plot(x_values, regression_line, color='blue', linewidth=2, label='Linear Regression')\n",
    "\n",
    "# Add formula text and r-value\n",
    "formula_text = f'y = {slope:.2f}x + {intercept:.2f}\\nRÂ² = {r_value**2:.3f}'\n",
    "plt.annotate(formula_text, xy=(0.05, 0.95), xycoords='axes fraction', \n",
    "             fontsize=12, bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"white\", alpha=0.8))\n",
    "\n",
    "plt.ylabel('Max Average Speed (km/h)')\n",
    "plt.xlabel('Max Average Heart Rate (bpm)')\n",
    "plt.title('Max Average Heart Rate vs Max Average Speed')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "hr_list= [140,150,160,170,180,185,190,195,200]\n",
    "for hr in hr_list:\n",
    "    speed = slope * hr + intercept\n",
    "    print(f\"Heart Rate: {hr} bpm, Speed: {speed:.1f} km/h\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe11a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot max_avg_hr and speed together for comparison\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plot speed profile (x-axis)\n",
    "plt.scatter( list(max_avg_additional_values.values())   , list(max_avg_speeds.values()),\n",
    "         linewidth=2, s=80, color='green', label='Speed vs Heart Rate')\n",
    "\n",
    "# Add linear regression\n",
    "y_values = list(max_avg_speeds.values())\n",
    "x_values = list(max_avg_additional_values.values())\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(x_values, y_values)\n",
    "regression_line = slope * np.array(x_values) + intercept\n",
    "plt.plot(x_values, regression_line, color='blue', linewidth=2, label='Linear Regression')\n",
    "\n",
    "# Add formula text and r-value\n",
    "formula_text = f'y = {slope:.2f}x + {intercept:.2f}\\nRÂ² = {r_value**2:.3f}'\n",
    "plt.annotate(formula_text, xy=(0.05, 0.95), xycoords='axes fraction', \n",
    "             fontsize=12, bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"white\", alpha=0.8))\n",
    "\n",
    "plt.ylabel('Max Average Speed (km/h)')\n",
    "plt.xlabel('Max Average Heart Rate (bpm)')\n",
    "plt.title('Max Average Heart Rate vs Max Average Speed')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "hr_list= [140,150,160,170,180,185,190,195,200]\n",
    "for hr in hr_list:\n",
    "    speed = slope * hr + intercept\n",
    "    print(f\"Heart Rate: {hr} bpm, Speed: {speed:.1f} km/h\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755ecde9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
