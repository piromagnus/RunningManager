{
  "master": {
    "tasks": [
      {
        "id": 1,
        "title": "Project scaffolding, configuration, and FR locale formatting",
        "description": "Initialize Streamlit multi-page app, environment configuration, directory structure, FR locale display utilities, and dependency management.",
        "details": "Implementation:\n- Structure:\n  - app.py (entry with Streamlit multipage; landing route to Dashboard)\n  - pages/: Dashboard.py, Athlete.py, Planner.py, Activities.py, Goals.py, Analytics.py, Settings.py\n  - services/: strava_service.py, garmin_import_service.py, garmin_export_service.py, linking_service.py, analytics_service.py, templates_service.py, timeseries_service.py\n  - persistence/: csv_storage.py, repositories.py\n  - utils/: formatting.py (fr-FR), crypto.py (Fernet), ids.py (uuid4), time.py (week boundaries ISO), auth_state.py (session state helpers)\n  - data/: activities.csv, planned_sessions.csv, links.csv, metrics.csv, thresholds.csv, goals.csv, athlete.csv, settings.csv, tokens.csv, timeseries/, raw/strava/\n- Requirements (requirements.txt): streamlit>=1.37, pandas>=2.2, numpy>=2, altair>=5, plotly>=5, requests>=2.32, python-dotenv>=1.0, cryptography>=43, garminconnect>=0.2.15, fitparse>=1.2.0, lxml>=5.2, portalocker>=2.10, babel>=2.15\n- .env and secrets:\n  - .env.example: STRAVA_CLIENT_ID=, STRAVA_CLIENT_SECRET=, DATA_DIR=./data, ENCRYPTION_KEY= (Fernet base64 key), STRAVA_REDIRECT_URI=http://localhost:8501\n  - Generate encryption key once: from cryptography.fernet import Fernet; print(Fernet.generate_key())\n- FR locale formatting utilities (utils/formatting.py):\n  - Use Babel: format_decimal(value, locale='fr_FR') for UI display; speeds in km/h; distances km/m; keep '.' in CSV storage\n  - Helpers: fmt_km(x)->'12,3 km', fmt_m(x)->'350 m', fmt_speed_kmh(x)->'9,4 km/h'\n- Streamlit app wiring:\n  - app.py: st.set_page_config(page_title='Running Manager', layout='wide'); provide navigation via pages directory\n- Session state keys: current_athlete_id, coach_settings, oauth_state, strava_tokens (not storing raw in session after encrypting to disk)\nPseudocode (app.py):\n  import streamlit as st\n  from utils.formatting import set_locale\n  set_locale('fr_FR')\n  st.title('Running Manager')\n  st.write('Use sidebar to navigate')\nSecurity:\n- Never log secrets; ensure .env in .gitignore; encryption key not committed\n",
        "testStrategy": "- Smoke test: streamlit run app.py, verify pages render and FR formatting shows decimal comma.\n- Unit tests for utils/formatting: assert '1 234,5' style using fr_FR; verify speed/dist formatting.\n- Verify .env loading via python-dotenv and default DATA_DIR creation.\n- Lint with ruff/flake8; pin versions in requirements.txt.",
        "priority": "medium",
        "dependencies": [],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Scaffold repository, directories, and placeholder files",
            "description": "Create the Streamlit project skeleton with the prescribed layout, placeholder modules, data directories, and .gitignore. Do not wire logic yet; just ensure the structure exists so later subtasks can fill in implementations.",
            "dependencies": [],
            "details": "Implementation steps:\n- Initialize repo root and create directories: pages/, services/, persistence/, utils/, data/, data/timeseries/, data/raw/strava/.\n- Create root files:\n  - app.py (minimal placeholder; will be wired in a later subtask)\n  - requirements.txt (left empty for now; filled in Subtask 2)\n  - .gitignore with at least: .env, .env.*, __pycache__/, .pytest_cache/, .streamlit/, .vscode/, .DS_Store, .idea/, data/tokens*, data/raw/, data/timeseries/, .python-version\n- Create pages stubs: pages/Dashboard.py, pages/Athlete.py, pages/Planner.py, pages/Activities.py, pages/Goals.py, pages/Analytics.py, pages/Settings.py. Each file: add a simple print or Streamlit title placeholder like `st.title('PageName')` so Streamlit recognizes them.\n- Create services stubs: strava_service.py, garmin_import_service.py, garmin_export_service.py, linking_service.py, analytics_service.py, templates_service.py, timeseries_service.py with module docstrings and TODOs.\n- Create persistence stubs: csv_storage.py, repositories.py with module docstrings and TODOs.\n- Create utils stubs: formatting.py, crypto.py, ids.py, time.py, auth_state.py with module docstrings and TODOs.\n- Create data placeholder CSVs (empty files for now): activities.csv, planned_sessions.csv, links.csv, metrics.csv, thresholds.csv, goals.csv, athlete.csv, settings.csv, tokens.csv.\n- Ensure file encodings are UTF-8 and that all new files include a minimal header/comment indicating intended purpose.",
            "status": "done",
            "testStrategy": "Manual check: run `tree` (or list directories) and verify the exact structure and filenames exist. Run `streamlit run app.py` to ensure it does not crash due to missing files (it can be a no-op at this stage). Verify .env is ignored by Git."
          },
          {
            "id": 2,
            "title": "Set up dependency management and install base requirements",
            "description": "Populate requirements.txt with pinned minimum versions, create a virtual environment, and install dependencies. Optionally add dev tooling configuration.",
            "dependencies": [
              "1.1"
            ],
            "details": "Implementation steps:\n- Populate requirements.txt with the provided specs (one per line):\n  - streamlit>=1.37\n  - pandas>=2.2\n  - numpy>=2\n  - altair>=5\n  - plotly>=5\n  - requests>=2.32\n  - python-dotenv>=1.0\n  - cryptography>=43\n  - garminconnect>=0.2.15\n  - fitparse>=1.2.0\n  - lxml>=5.2\n  - portalocker>=2.10\n  - babel>=2.15\n- Create and activate a virtual environment (e.g., Python 3.11+). Install packages with `pip install -r requirements.txt`.\n- Optional dev tooling (recommended): add ruff and pytest to a separate requirements-dev.txt and configure a basic pyproject.toml for ruff rules. This is optional and not required for runtime.\n- Verify Streamlit and Babel import cleanly in a Python REPL.",
            "status": "done",
            "testStrategy": "Run `python -c \"import streamlit, pandas, numpy, altair, plotly, requests, dotenv, cryptography, fitparse, lxml, portalocker; from babel import numbers; print('ok')\"` and confirm no ImportErrors. Optionally run `pip check` to verify dependency consistency."
          },
          {
            "id": 3,
            "title": "Environment configuration and secrets loader (.env, .env.example, config utility)",
            "description": "Create .env.example, ensure .env is git-ignored, and implement a configuration utility to load environment variables, validate them, and provision directories.",
            "dependencies": [
              "1.1",
              "1.2"
            ],
            "details": "Implementation steps:\n- Add .env.example with the exact keys:\n  - STRAVA_CLIENT_ID=\n  - STRAVA_CLIENT_SECRET=\n  - DATA_DIR=./data\n  - ENCRYPTION_KEY=\n  - STRAVA_REDIRECT_URI=http://localhost:8501\n  Include a comment showing how to generate the encryption key once: `from cryptography.fernet import Fernet; print(Fernet.generate_key())`.\n- Ensure .env and any .env.local are in .gitignore (already added in Subtask 1).\n- Implement utils/config.py:\n  - Use python-dotenv to load .env if present.\n  - Define a Config object (dataclass or NamedTuple) with fields: strava_client_id, strava_client_secret, strava_redirect_uri, data_dir (default './data' if not provided), encryption_key (required for crypto operations), plus derived paths for data subdirs (timeseries, raw/strava).\n  - Provide load_config() that: loads env vars, validates minimal requirements (DATA_DIR always set; STRAVA_* can be empty in dev but warn; ENCRYPTION_KEY required for crypto operations), expands and creates directories (DATA_DIR, DATA_DIR/timeseries, DATA_DIR/raw/strava) if missing, and never logs secret values.\n  - Provide helper get_fernet() that returns a Fernet instance if encryption_key is present; otherwise raises a clear error instructing how to generate one.\n  - Ensure any logging sanitizes secrets by masking values.\n- Reference: later modules import from utils.config to access configuration.",
            "status": "done",
            "testStrategy": "Create a local .env from .env.example with dummy values and a valid Fernet key. Run a small script to call load_config() and assert directories are created. Confirm that secrets are not printed in logs. Remove ENCRYPTION_KEY temporarily and assert a clear error is raised when calling get_fernet()."
          },
          {
            "id": 4,
            "title": "Implement FR locale formatting utilities (utils/formatting.py)",
            "description": "Provide FR locale display helpers using Babel for decimals, and unit-specific formatters for km, meters, and km/h. Include a set_locale helper and ensure storage uses '.' while UI uses ',' decimal comma.",
            "dependencies": [
              "1.1",
              "1.2"
            ],
            "details": "Implementation steps:\n- In utils/formatting.py implement:\n  - A module-level LOCALE defaulting to 'fr_FR' and set_locale(locale_str='fr_FR') to update it (validate with Babel Locale parsing; fall back to fr_FR on error).\n  - fmt_decimal(value, digits=None): format with babel.numbers.format_decimal using LOCALE, optional fixed fraction digits when provided; handle None by returning an empty string.\n  - fmt_km(x): convert meters to km if x is in meters elsewhere or expect km directly per app convention; for this task, assume input is kilometers; format with one decimal (e.g., 12,3 km) and append unit with a non-breaking space before 'km'.\n  - fmt_m(x): format integer meters with thousands grouping per FR, append non-breaking space and 'm'.\n  - fmt_speed_kmh(x): format numeric speed in km/h with one decimal (e.g., 9,4 km/h), append unit with non-breaking space before 'km/h'.\n  - Note: Use Babel for UI display; do not alter storage: when writing numbers to CSV, keep '.' as decimal separator. Provide helper to_str_storage(x, ndigits=None) that returns a string with '.' decimal using Python formatting.\n- Be robust to None/NaN by returning '' for display helpers.\n- Update module docstring with examples.\n- Add import and use of set_locale('fr_FR') will be wired in app.py later.",
            "status": "done",
            "testStrategy": "Unit tests: assert fmt_decimal(1234.5) == '1 234,5'; fmt_km(12.3) == '12,3 km'; fmt_m(350) == '350 m'; fmt_speed_kmh(9.4) == '9,4 km/h'. Verify set_locale('fr_FR') impacts formatting. Confirm to_str_storage(12.3) returns '12.3'."
          },
          {
            "id": 5,
            "title": "Wire Streamlit app initialization, FR locale, and session state helpers",
            "description": "Connect app.py to configuration and formatting, implement session state helpers and basic utility modules, and ensure the multipage app renders with FR formatting. Verify data files and directories exist.",
            "dependencies": [
              "1.1",
              "1.3",
              "1.4"
            ],
            "details": "Implementation steps:\n- Implement utils/auth_state.py:\n  - Define constants for session keys: CURRENT_ATHLETE_ID, COACH_SETTINGS, OAUTH_STATE, STRAVA_TOKENS.\n  - Provide init_session_state() to set defaults if missing (e.g., current_athlete_id=None, coach_settings={}, oauth_state=None, strava_tokens_meta={'hasTokens': False}). Do not store raw tokens; only store metadata (e.g., presence and expiry) if needed.\n  - Provide getters/setters with small wrappers around st.session_state.\n- Implement utils/ids.py: new_id() returning uuid4 as string.\n- Implement utils/time.py: helpers using datetime/date and ISO calendar:\n  - iso_week_start(date) -> Monday 00:00:00 of that ISO week.\n  - iso_week_end(date) -> Sunday 23:59:59.999999 of that ISO week.\n  - today_local() helper.\n- Update app.py to:\n  - Import streamlit as st, utils.formatting.set_locale, and utils.config.load_config.\n  - Call st.set_page_config(page_title='Running Manager', layout='wide').\n  - Call load_config() on startup and set_locale('fr_FR').\n  - Initialize session state via utils.auth_state.init_session_state().\n  - Render a simple landing: title 'Running Manager' and text 'Use sidebar to navigate'. Streamlit will automatically provide sidebar navigation for files under pages/.\n  - Do not print or log secrets from config. Optionally render resolved DATA_DIR path for debugging without showing sensitive values.\n- Ensure data directory structure exists (already handled in load_config). If placeholder CSVs were not created in Subtask 1, add a small guard in app startup to create empty files for the known CSV filenames.\n- Keep services and persistence modules as stubs; no runtime import beyond config/formatting/auth_state/ids/time to keep boot fast.",
            "status": "done",
            "testStrategy": "Smoke test: run `streamlit run app.py` and verify the title renders, pages appear in the sidebar, and a quick demo of FR formatting (e.g., st.write(fmt_km(12.3))) shows a decimal comma. Validate session state keys exist via st.session_state. Confirm no secrets are logged. Verify DATA_DIR and subdirectories exist."
          }
        ]
      },
      {
        "id": 2,
        "title": "CSV persistence layer and repositories",
        "description": "Implement CSV storage abstraction with repositories for activities, planned sessions, links, metrics, thresholds, goals, athletes, settings, and tokens. Ensure schema adherence and safe concurrent access.",
        "details": "Files and schemas (headers exactly as PRD):\n- activities.csv: activityId, athleteId, source, startTime, distanceKm, elapsedSec, movingSec, ascentM, avgHr, maxHr, hasTimeseries, polyline, rawJsonPath\n- planned_sessions.csv: plannedSessionId, athleteId, date, type, plannedDistanceKm, plannedDurationSec, plannedAscentM, targetType, targetLabel, notes, stepEndMode\n- links.csv: linkId, plannedSessionId, activityId, matchScore, rpe(1-10), comments\n- metrics.csv: periodStart, periodEnd, distanceKm, timeSec, ascentM, distanceEqKm, intenseTimeSec, easyTimeSec, numSessions, adherencePct\n- thresholds.csv: thresholdId, athleteId, name, hrMin, hrMax, paceFlatKmhMin, paceFlatKmhMax, ascentRateMPerHMin, ascentRateMPerHMax\n- goals.csv: goalId, athleteId, date, distanceKm, ascentM, terrain, priority, targetTimeSec, isRace\n- athlete.csv: athleteId, coachId, name, thresholdsProfileId, units\n- settings.csv: coachId, units, distanceEqFactor\n- tokens.csv: athleteId, provider, accessTokenEnc, refreshTokenEnc, expiresAt\n- timeseries/: {activityId}.csv with columns: timestamp, hr, paceKmh, elevationM, cadence, lat, lon\nImplementation:\n- persistence/csv_storage.py:\n  - class CsvStorage(base_dir): read_csv(path, dtypes), write_csv(path, df), append_row(path, dict), upsert(path, key_cols, row), file lock via portalocker to prevent races; ensure index=False; NA handling\n  - Use pandas to enforce types; ensure numeric '.' locale\n- persistence/repositories.py:\n  - ActivitiesRepo, PlannedSessionsRepo, LinksRepo, MetricsRepo, ThresholdsRepo, GoalsRepo, AthletesRepo, SettingsRepo, TokensRepo\n  - Each repo exposes: list(filter), get(id), create(row), update(id, updates), delete(id)\n  - ID generation via utils/ids.uuid() (UUID4 strings) if id missing\n- utils/time.py:\n  - week_start(date)->Monday 00:00; week_end(date)->Sunday 23:59:59\nPseudocode:\n  class ActivitiesRepo:\n      def create_from_strava(self, payload):\n          row = map_strava(payload); self.create(row)\n  class TokensRepo:\n      def save(self, athleteId, provider, accessTokenEnc, refreshTokenEnc, expiresAt): upsert\nValidation:\n- Initialize empty CSVs with headers if not exist\n- Ensure directories exist (data/, data/timeseries/, data/raw/strava/)\n",
        "testStrategy": "- Unit tests with pytest + tmp_path for each repo CRUD (create/list/get/update/delete).\n- Concurrency test: simulate two writers with threads; portalocker prevents corruption.\n- Schema test: write rows with missing columns should raise; dtypes respected.\n- Timeseries save/load roundtrip maintains columns and order.",
        "priority": "medium",
        "dependencies": [],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Define CSV schemas and bootstrap data directories/files",
            "description": "Create centralized schema definitions and ensure the data directory structure and empty CSV files with exact PRD headers exist.",
            "dependencies": [],
            "details": "Create persistence/schemas.py with:\n- SCHEMAS: dict mapping table name -> ordered list of column names, exactly as PRD specifies (preserve case and special characters like 'rpe(1-10)').\n- DTYPES: dict mapping table name -> pandas dtype map for each column (e.g., strings/object for IDs and text; float for distanceKm/ascentM; int for *_Sec; bool for hasTimeseries/isRace; datetime64[ns] for startTime/date/periodStart/periodEnd/expiresAt). Define parse_dates sets for date/time columns.\n- FILE_NAMES: mapping from logical table key to filename.\n\nImplement persistence/bootstrap.py:\n- def ensure_data_layout(base_dir: str) -> dict[str, str]:\n  - Create directories: {base_dir}/data, {base_dir}/data/timeseries, {base_dir}/data/raw/strava using pathlib with exist_ok=True.\n  - For each CSV per PRD, ensure the file exists. If missing, create with a single header row using csv.DictWriter with the exact SCHEMAS order and no data rows.\n  - Return resolved absolute paths for each file (e.g., {'activities': '/.../data/activities.csv', ...}).\n- def validate_columns_exact(table: str, columns: list[str]) -> None: Raise ValueError if the provided columns are not exactly equal and in the same order as SCHEMAS[table].\n\nNotes:\n- Keep all headers exactly as PRD. In particular: links.csv must include 'rpe(1-10)'.\n- Use UTF-8 encoding consistently.\n- Avoid adding index columns at any point.\n- Do not attempt to coerce locale-specific formats in schemas; use dot-decimal numeric representation throughout.",
            "status": "done",
            "testStrategy": "Unit test ensure_data_layout using tmp_path: directories created and CSVs initialized with exact headers and zero data rows. Test validate_columns_exact with matching and mismatched columns. Verify that files are re-entrant (running twice does not alter files)."
          },
          {
            "id": 2,
            "title": "Implement CsvStorage with locking, atomic writes, and dtype enforcement",
            "description": "Build the storage abstraction providing read/write/append/upsert with safe concurrent access and schema/dtype enforcement.",
            "dependencies": [
              "2.1"
            ],
            "details": "Create persistence/csv_storage.py with class CsvStorage(base_dir: str):\n- __init__: call ensure_data_layout(base_dir) and store absolute file paths. Preload SCHEMAS/DTYPES/parse_dates from persistence.schemas.\n- Internal helpers:\n  - _lock(path, mode): context manager using portalocker.Lock(path, flags=EXCLUSIVE for writes/updates/appends; SHARED for reads) with timeout and proper newline/encoding handling.\n  - _atomic_write(path, df): write to a temporary file in the same directory (NamedTemporaryFile(delete=False)), then os.replace(temp_path, path) to ensure atomicity on most OSes.\n  - _coerce_df(table, df): reorder columns to SCHEMAS[table], coerce dtypes per DTYPES[table], parse dates for configured columns; ensure NaNs for missing numeric fields.\n  - _validate_table(table): ensure table known; reuse validate_columns_exact for consistency when writing/append.\n\nPublic methods:\n- read_csv(table: str) -> pd.DataFrame: acquire SHARED lock, read with pandas.read_csv using dtype=DTYPES[table] where applicable and parse_dates for configured columns. Ensure columns exactly match schema order. Return empty DataFrame with columns if file has no rows.\n- write_csv(table: str, df: pd.DataFrame) -> None: validate schema, coerce types, acquire EXCLUSIVE lock, then _atomic_write. Always index=False, header=True. Ensure float formatting uses dot-decimal (default for pandas; do not use locale formats).\n- append_row(table: str, row: dict) -> None: validate keys cover exactly SCHEMAS[table] (allow missing keys filled with None). Acquire EXCLUSIVE lock, open the file in append mode and write exactly one row with csv.DictWriter using SCHEMAS[table] order. Normalize None to '' for string columns and keep numeric NaNs handled by pandas on next read.\n- upsert(table: str, key_cols: list[str], row: dict) -> None: EXCLUSIVE lock, read entire table to DataFrame, locate existing row by equality on key_cols; if found, update specified fields; otherwise append new row; write back using _atomic_write. Validate that key_cols are in SCHEMAS[table].\n- delete_where(table: str, predicate) -> int: EXCLUSIVE lock, load df, filter out rows matching predicate, write back; return count deleted.\n\nImplementation details:\n- Use newline='' and encoding='utf-8' for csv module writes to avoid extra CRLFs.\n- Ensure index=False in all writes.\n- Missing values: write empty strings for object columns; numeric NaNs will be empty fields; booleans as True/False.\n- Prefer shared locks for read_csv to allow concurrent readers, exclusive locks for write/upsert/delete to prevent races.\n- Provide get_path(table) to expose full path for debugging.\n- Ensure portalocker is added as a dependency and imported.\n",
            "status": "done",
            "testStrategy": "Unit tests with pytest: read/write roundtrip for each table; append_row writes a single new line; upsert inserts then updates by key; delete_where removes expected rows. Concurrency test: spawn two threads attempting upsert on same keys; assert file remains valid CSV and final content reflects serialized updates (no partial or duplicated headers). Schema test: writing df with wrong order or unknown column raises."
          },
          {
            "id": 3,
            "title": "Implement repositories and ID generation utility",
            "description": "Add repository classes for all entities with CRUD methods, filtering, and special helpers for activities and tokens. Provide UUID generation utility.",
            "dependencies": [
              "2.2"
            ],
            "details": "Create utils/ids.py with:\n- def uuid() -> str: return str(uuid.uuid4()).\n\nCreate persistence/repositories.py:\n- BaseRepo: constructor takes storage: CsvStorage, table: str, id_col: str (or None if composite), key_cols (optional for upsert-based repos). Common helpers:\n  - _ensure_id(row): if id_col and not provided, set row[id_col] = utils.ids.uuid().\n  - _normalize(row): ensure all SCHEMAS[table] keys present (fill with None) and types are compatible (let storage handle final coercion).\n  - list(filter: dict|callable|None) -> list[dict]: load df via storage.read_csv; if filter is dict, apply equality for provided columns; if callable, apply predicate over dict rows; return list of dicts.\n  - get(id_val) -> dict|None: return first row where id_col == id_val.\n  - create(row: dict) -> dict: _ensure_id, _normalize; storage.append_row; return created row.\n  - update(id_val, updates: dict) -> dict: load df, locate by id_col; apply updates; storage.write_csv with modified df; return updated row; raise KeyError if not found.\n  - delete(id_val) -> bool: delete_where with predicate row[id_col]==id_val; return True if deleted.\n\nImplement concrete repos:\n- ActivitiesRepo(table='activities', id_col='activityId'): plus def create_from_strava(payload: dict) -> dict:\n  - Map payload to normalized row: athleteId, source='strava', startTime, distanceKm, elapsedSec, movingSec, ascentM, avgHr, maxHr, hasTimeseries=False, polyline (from map/summary_polyline if present), rawJsonPath (write raw JSON to base_dir/data/raw/strava/{activityId}.json and store relative path). Generate activityId if missing. Use storage.append_row.\n- PlannedSessionsRepo('planned_sessions', 'plannedSessionId')\n- LinksRepo('links', 'linkId'): support rpe field named exactly 'rpe(1-10)'.\n- MetricsRepo('metrics', id_col=None): provide list and delete only; no single-row get by ID since no ID column. Consider create/update via upsert with key ['periodStart','periodEnd','athleteId'] if athleteId added; if not, limit to append-only as per schema provided.\n- ThresholdsRepo('thresholds', 'thresholdId')\n- GoalsRepo('goals', 'goalId')\n- AthletesRepo('athlete', 'athleteId')\n- SettingsRepo('settings', id_col=None): upsert by key ['coachId'] for single settings per coach.\n- TokensRepo('tokens', id_col=None): def save(athleteId, provider, accessTokenEnc, refreshTokenEnc, expiresAt): storage.upsert('tokens', ['athleteId','provider'], {...}). Also expose get(athleteId, provider).\n\nNotes:\n- Repos should not alter column names; keep exact schema order.\n- For list(filter: dict), only equality is required; allow passing lambda row: bool for more complex queries.\n- Avoid reading/writing index; all persistence through CsvStorage methods to inherit locking and dtype enforcement.",
            "status": "done",
            "testStrategy": "Unit tests for each repo with tmp_path storage: CRUD happy paths and edge cases (update non-existent -> KeyError, delete non-existent -> False). ActivitiesRepo.create_from_strava stores payload under data/raw/strava and writes rawJsonPath; TokensRepo.save performs upsert (second call updates, not duplicates). Verify LinksRepo respects 'rpe(1-10)' column name. Verify SettingsRepo upsert by coachId."
          },
          {
            "id": 4,
            "title": "Implement timeseries storage and integration with activities",
            "description": "Add dedicated read/write helpers for timeseries/{activityId}.csv with correct columns and locking; update activities.hasTimeseries on save.",
            "dependencies": [
              "2.2",
              "2.3"
            ],
            "details": "Create persistence/timeseries.py with class TimeseriesRepo:\n- __init__(storage: CsvStorage): keep reference to storage and base_dir.\n- _schema = ['timestamp','hr','paceKmh','elevationM','cadence','lat','lon'] with DTYPES: timestamp as int or datetime64[ns] (choose one and be consistent; for MVP use int epoch seconds), hr/cadence as float or int, paceKmh/elevationM/lat/lon as float.\n- _path(activityId): {base_dir}/data/timeseries/{activityId}.csv.\n- save(activityId: str, df_or_rows):\n  - Ensure directory exists (bootstrap already created).\n  - If input is list[dict], convert to DataFrame; else accept DataFrame. Reorder columns to _schema, coerce types.\n  - Acquire EXCLUSIVE lock on the file path using portalocker; write CSV atomically (header=True, index=False, UTF-8). If file exists, replace entirely (no partial append) to keep a clean single source of truth.\n  - After successful write, set activities.hasTimeseries=True for the activity via ActivitiesRepo.update(activityId, {'hasTimeseries': True}).\n- load(activityId: str) -> pd.DataFrame: Acquire SHARED lock; if file missing, return empty DataFrame with _schema columns; else read via pandas.read_csv with dtype mapping.\n- exists(activityId: str) -> bool.\n\nNotes:\n- Do not add extra columns beyond _schema; reject unexpected fields with ValueError.\n- Maintain dot-decimal floats; do not localize numeric formatting.\n- Keep this logic independent from Strava mapping (implemented in Task 5) but ready to be called from it.",
            "status": "done",
            "testStrategy": "Unit tests: save then load roundtrip preserves number of rows and column order; hr/paceKmh numeric types preserved. Verify that after save, activities.hasTimeseries is True. Concurrency: two threads attempting to save to the same activity should serialize, resulting in one final valid file (last writer wins) without corruption."
          },
          {
            "id": 5,
            "title": "Add time utilities and comprehensive test suite wiring",
            "description": "Implement week_start/week_end utilities and create pytest suites covering storage, repositories, schemas, and concurrency.",
            "dependencies": [
              "2.3",
              "2.4"
            ],
            "details": "Implement utils/time.py:\n- week_start(date_or_dt): return a datetime at Monday 00:00:00 of the week containing the given date (timezone-naive, or respect input tz consistently). Use date.isoweekday() to compute delta.\n- week_end(date_or_dt): return Sunday 23:59:59 of the same week (week_start + 6 days + 23:59:59).\n\nTesting setup:\n- Add tests/ with fixtures for tmp_path storage instance (CsvStorage(tmp_path)).\n- Tests for CsvStorage (2.2): schema enforcement, atomic write behavior (simulate crash by raising between temp creation and replace in a monkeypatched function), dtype coercion, NA handling, decimal dot verification in written files.\n- Tests for Repos (2.3): CRUD across all repos; tokens upsert; activities from strava mapping stub writes raw JSON file and sets rawJsonPath.\n- Tests for Timeseries (2.4): save/load roundtrip and activities.hasTimeseries flip.\n- Concurrency tests: use threading where two writers call upsert or save concurrently; assert no CSV duplication of headers, no partial lines; file remains readable by pandas.\n- Schema tests (2.1): verify created headers match PRD exactly including special names like 'rpe(1-10)'.",
            "status": "done",
            "testStrategy": "Run pytest locally; ensure coverage across modules. Add a slow marker for concurrency tests if needed. CI can run tests in parallel to surface any locking path issues. Validate that week_start/week_end behave across month/year boundaries."
          }
        ]
      },
      {
        "id": 3,
        "title": "Athlete and Settings UI with thresholds and token encryption",
        "description": "Build Athlete and Settings pages for managing athlete profile, thresholds, units/locale, distance-equivalent factor, and connected accounts. Implement encrypted storage for OAuth tokens.",
        "details": "Settings page (Streamlit):\n- Coach settings: units (km/m), speed display (km/h), decimal style (fr-FR comma, display only), distanceEqFactor (default 0.01)\n- Integrations section: Connect Strava button (launches OAuth flow), Garmin login (email/password prompt for session; do not store password)\nAthlete page:\n- Profile fields: athlete name, units, thresholdsProfileId\n- Thresholds CRUD: entries per PRD columns; Fundamental uses hrMax and optional pace; MVA includes HR + flat pace ranges; optional ascent rate\nToken encryption:\n- utils/crypto.py exposes encrypt(text)->base64, decrypt(token)\n- Use cryptography.Fernet with ENCRYPTION_KEY from .env\n- Save tokens to tokens.csv via TokensRepo with encrypted access/refresh tokens and expiresAt\nUI behaviors:\n- Inputs display using fr-FR formatting helpers; store numeric with '.'\nPseudocode (encryption):\n  from cryptography.fernet import Fernet\n  f = Fernet(os.getenv('ENCRYPTION_KEY'))\n  enc = f.encrypt(access_token.encode()).decode()\n  dec = f.decrypt(enc.encode()).decode()\n",
        "testStrategy": "- Manual UI test: create athlete, set units, thresholds, distanceEqFactor; verify persistence to CSVs.\n- Unit test: encrypt/decrypt roundtrip; tokens.csv contains non-plaintext tokens.\n- Verify formatting: inputs accept comma display but saves '.' to CSV (e.g., '12,5' -> 12.5 stored).\n- Negative test: missing ENCRYPTION_KEY blocks token save with clear error.",
        "priority": "medium",
        "dependencies": [],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 4,
        "title": "Planner page with session editor and week templates",
        "description": "Implement session creation/editing for Fundamental Endurance, Long Run, and Simple Intervals; calendar/week view; save/apply week templates. Use separate threshold names 'Threshold 60' and 'Threshold 30' (replacing any prior 'Threshold 60/30') across target labels, lookups, and examples. [Updated: 07/10/2025]",
        "status": "pending",
        "dependencies": [],
        "priority": "medium",
        "details": "Planner features:\n- Week view (Mon–Sun) for single athlete; add/edit/delete planned sessions\n- Session types:\n  - FUNDAMENTAL_ENDURANCE: plannedDurationSec (required), optional HR cap (targetType='hr', targetLabel) and optional pace; show estimated km from thresholds (Fundamental pace) or recent easy-run pace fallback. Target labels that reference thresholds should use the new names where relevant (e.g., 'Threshold 60', 'Threshold 30'); 'Fundamental' threshold name remains unchanged for estimation.\n  - LONG_RUN: plannedDistanceKm (required), plannedAscentM (optional), plannedDurationSec (optional), optional HR/pace threshold target. When selecting a threshold-based target, use explicit names 'Threshold 60' or 'Threshold 30' (no 'Threshold 60/30').\n  - INTERVAL_SIMPLE: structure JSON with warmupSec, repeats[{workSec, recoverSec, targetType(hr|pace|sensation), targetLabel}], cooldownSec; stepEndMode for intervals (auto|lap). For threshold-based targets, targetLabel must reference discrete threshold names, e.g., 'Threshold 60' or 'Threshold 30'. Remove any usage or example of 'Threshold 60/30'.\n- Data writes to planned_sessions.csv; store structured JSON steps serialized in a 'notes' or additional field; per PRD, planned_sessions.csv has 'notes' and 'stepEndMode'; include steps JSON in an additional column 'stepsJson' (extend schema in repo with backward-compat handling). stepsJson should preserve the targetLabel strings exactly as selected (e.g., 'Threshold 60', 'Threshold 30').\n- Week templates:\n  - templates_service: save week pattern as templates.csv (columns: templateId, name, stepsJson)\n  - Copy/apply a template to selected week (shift dates)\n  - Ensure templates allow and preserve the new discrete threshold names in stepsJson (e.g., repeats[].targetLabel='Threshold 60' or 'Threshold 30').\nThreshold lookups and examples:\n- Threshold name updates: replace any references to 'Threshold 60/30' with discrete names 'Threshold 60' and 'Threshold 30' across Planner requirements (UI labels, interval target labels, and any examples/documentation shown in the UI).\n- Target resolution: when targetType in a step/session implies a threshold-based target ('hr' or 'pace'), resolve targetLabel against thresholds_repo by exact name match. Accepted examples include 'Threshold 60' and 'Threshold 30'.\nEstimated km for Fundamental:\n- Look up thresholds for Fundamental: use paceFlatKmhMax or average range; estimated_km = (plannedDurationSec / 3600) * pace_kmh\n- Fallback: compute median pace from last 4 easy/fundamental activities\nPseudocode:\n  def estimate_km(duration_sec, athlete_id):\n      thr = thresholds_repo.find(athlete_id, name='Fundamental')\n      if thr and thr.paceFlatKmhMax: pace = (thr.paceFlatKmhMin+thr.paceFlatKmhMax)/2\n      else: pace = recent_easy_pace(athlete_id)\n      return (duration_sec/3600.0)*pace\n  def resolve_threshold_target(athlete_id, target_label):\n      # target_label examples: 'Threshold 60', 'Threshold 30', 'Fundamental'\n      return thresholds_repo.find(athlete_id, name=target_label)\nUI:\n- Streamlit forms per session type; calendar grid by date; drag-copy optional later; template save/apply buttons\n- For targets that reference thresholds: provide a select populated from the athlete's thresholds names, explicitly including 'Threshold 60' and 'Threshold 30' (remove any 'Threshold 60/30' option). Persist selected names verbatim in stepsJson/targetLabel.\n\n<info added on 2025-10-07T08:22:42.888Z>\nSubtask 10:\n- Title: Backend unit test suite for Planner repositories and services\n- Description: Implement comprehensive unit tests for backend components supporting the Planner, covering repositories, services, and serialization with emphasis on exact preservation of discrete threshold names ('Threshold 60', 'Threshold 30') and CSV schema migration.\n- Status: pending\n- Dependencies: 4.5, 4.6, 4.9\n- Details:\n  - Framework: pytest with tmp_path for isolated filesystem and monkeypatch for repo/service mocks.\n  - Components under test:\n    - PlannedSessionsRepo: migration when stepsJson column is missing; CRUD with stepsJson and stepEndMode; exact string preservation of targetLabel.\n    - TemplatesRepo: CRUD using templates.csv; save/load of stepsJson arrays containing sessions; exact preservation of targetLabel strings.\n    - Serialization helpers: serialize_steps and deserialize_steps roundtrip behavior, including None -> '' and '' -> None.\n    - planner_service helpers: list_threshold_names ordering and exclusion of 'Threshold 60/30'; resolve_threshold_target exact match behavior; recent_easy_pace median calculation; estimate_km fallback chain and default.\n    - templates_service: save_week_template and apply_week_template date shifting; preservation of stepsJson and stepEndMode; no mutation of targetLabel strings.\n  - Test data: mock thresholds including 'Fundamental', 'Threshold 30', 'Threshold 60'; mock activities for easy/fundamental runs to exercise recent_easy_pace.\n- Test Strategy:\n  - PlannedSessionsRepo:\n    - Create a CSV without stepsJson; load and save; assert header now includes stepsJson and existing rows have stepsJson=''.\n    - Create/update/read/delete a row with INTERVAL_SIMPLE stepsJson containing repeats with targetLabel='Threshold 60'; assert exact string equality on readback; stepEndMode preserved.\n    - Ensure repo does not alter row-level targetLabel strings for any type.\n  - TemplatesRepo:\n    - Save and load a template containing a mix of session types (including an interval) and verify stepsJson array equality and exact targetLabel strings ('Threshold 60'/'Threshold 30').\n  - Serialization:\n    - serialize_steps(None) == ''; deserialize_steps('') is None; roundtrip of a populated steps dict yields deep equality and compact JSON (separators applied).\n  - planner_service:\n    - list_threshold_names returns ['Fundamental', 'Threshold 30', 'Threshold 60', ...] in expected order; does not include 'Threshold 60/30'.\n    - resolve_threshold_target matches only exact names; returns None for 'Threshold 60/30' and unknown labels.\n    - recent_easy_pace computes median km/h from up to 4 recent easy/fundamental activities; returns None when no data.\n    - estimate_km uses Fundamental threshold average if available; falls back to recent_easy_pace; defaults to 9.0 km/h when both missing.\n  - templates_service:\n    - save_week_template creates a template with correct dateOffset values and preserves stepsJson/stepEndMode/targetLabel strings.\n    - apply_week_template writes sessions on correct target dates with identical persisted fields; verify CSV rows contain the same stepsJson and exact targetLabel strings.\n  - Negative/edge cases:\n    - Attempt to resolve a non-existent threshold name; assert None.\n    - Interval steps with targetType='sensation' preserve free-text targetLabel.\n    - Ensure no occurrence of 'Threshold 60/30' in any generated or persisted data.\n</info added on 2025-10-07T08:22:42.888Z>",
        "testStrategy": "- Create sessions for a week; verify planned_sessions.csv rows and fields (including stepEndMode) and that stepsJson persists targetLabel='Threshold 60' or 'Threshold 30' as selected.\n- Fundamental estimate displayed and matches thresholds values; update thresholds updates estimate. Verify that estimation logic remains unaffected by the threshold name change (still uses 'Fundamental').\n- Intervals: create an INTERVAL_SIMPLE with targetType='hr' and targetLabel='Threshold 60' and another with 'Threshold 30'; assert the UI resolves and displays the correct threshold values from thresholds_repo and that these labels round-trip through CSV/templates.\n- Save a week as template containing steps with targetLabel 'Threshold 60'/'Threshold 30'; apply to a future week; sessions created with correct shifted dates and preserved target labels.\n- Edge cases: intervals with lap end mode; validate structure JSON serialization/deserialization; ensure no 'Threshold 60/30' appears in any new UI options or persisted data.\n",
        "subtasks": [
          {
            "id": 1,
            "title": "Replace 'Threshold 60/30' with 'Threshold 60' and 'Threshold 30' in UI selectors and help text",
            "description": "",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "Update threshold lookup helpers to resolve 'Threshold 60' and 'Threshold 30' by exact name",
            "description": "",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "Ensure templates_service saves/applies stepsJson with the new threshold names unchanged",
            "description": "",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "Add tests for intervals targeting 'Threshold 60' and 'Threshold 30' and verify CSV/template roundtrip",
            "description": "",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 5,
            "title": "Extend planned_sessions schema with stepsJson and repos (backward compatible)",
            "description": "Add a new stepsJson column to planned_sessions.csv and update repositories to read/write it safely without breaking existing data. Prepare a TemplatesRepo for templates.csv. Ensure exact preservation of targetLabel strings in stepsJson.",
            "dependencies": [],
            "details": "Implementation steps:\n- Schema update:\n  - planned_sessions.csv currently: plannedSessionId, athleteId, date, type, plannedDistanceKm, plannedDurationSec, plannedAscentM, targetType, targetLabel, notes, stepEndMode.\n  - Extend to include a new optional column stepsJson (string). Keep existing order; append stepsJson at the end for simplicity.\n- Repository changes (persistence/repositories.py):\n  - PlannedSessionsRepo:\n    - On load: if stepsJson column missing, add it in-memory with empty string for each row; when saving, ensure file is written with stepsJson included. Implement a lightweight migration: when opening the CSV, check headers and rewrite with the new header including stepsJson if missing (existing rows get stepsJson='').\n    - Expose CRUD that accepts/returns stepsJson (string) and stepEndMode (string) along with existing fields.\n    - Do not transform targetLabel; store exactly as passed.\n  - Add helper functions:\n    - serialize_steps(steps_dict) -> str: json.dumps with ensure_ascii=False and separators to keep the string compact; None -> ''.\n    - deserialize_steps(steps_json) -> dict|None: if empty -> None else json.loads.\n  - TemplatesRepo:\n    - Backed by templates.csv with headers: templateId, athleteId, name, stepsJson.\n    - Template stepsJson will be a JSON array of planned session dicts (including dateOffset [0-6], type, plannedDistanceKm, plannedDurationSec, plannedAscentM, targetType, targetLabel, notes, stepEndMode, stepsJson for intervals). Keep targetLabel verbatim.\n- Services wiring:\n  - Update repositories factory to register TemplatesRepo.\n  - Ensure all repos use portalocker for concurrency (reuse from Task 2).\n- Data model notes:\n  - stepsJson is only required/non-empty for INTERVAL_SIMPLE; for other types, set '' or null-equivalent.\n  - Preserve targetLabel strings exactly (e.g., 'Threshold 60', 'Threshold 30', 'Fundamental').",
            "status": "done",
            "testStrategy": "Unit tests:\n- Repo migration: create a planned_sessions.csv without stepsJson; load via PlannedSessionsRepo; assert stepsJson is present in headers after a save; old rows get stepsJson=''.\n- CRUD roundtrip with stepsJson populated for an interval; assert exact string equality on readback and that targetLabel substrings ('Threshold 60') are intact.\n- TemplatesRepo CRUD: save a template with multiple sessions including an interval; reload and assert equality."
          },
          {
            "id": 6,
            "title": "Refactor threshold names and implement target resolution + estimation helpers",
            "description": "Remove any usage of 'Threshold 60/30' and replace with discrete 'Threshold 60' and 'Threshold 30' across UI options and examples. Implement resolve_threshold_target and estimate_km helpers used by the Planner.",
            "dependencies": [],
            "details": "Implementation steps:\n- thresholds naming:\n  - Search codebase for 'Threshold 60/30' and replace with explicit discrete names. Ensure UI select options will include 'Threshold 60' and 'Threshold 30' when thresholds exist for the athlete. Do not change 'Fundamental' threshold name.\n- Helpers (services/planner_service.py):\n  - list_threshold_names(athleteId): returns a list of threshold names from thresholds_repo for the athlete, ensuring any of ['Threshold 60','Threshold 30','Fundamental'] present are included as-is. Sort by a sensible order (Fundamental first, then Threshold 30, Threshold 60, then others) or by repo order.\n  - resolve_threshold_target(athleteId, target_label): exact name match via thresholds_repo.find(athleteId, name=target_label); return None if not found.\n  - recent_easy_pace(athleteId): compute median km/h from last up to 4 easy/fundamental activities. Use activities_repo listing sorted by startTime desc; filter by tags or low RPE if available; else fallback to last 4 runs overall. pace_kmh = distanceKm / (movingSec/3600). Return None if no data.\n  - estimate_km(duration_sec, athleteId):\n    - thr = thresholds_repo.find(athleteId, name='Fundamental'); if thr and thr.paceFlatKmhMax (and Min) exist, pace = (thr.paceFlatKmhMin + thr.paceFlatKmhMax)/2. Else pace = recent_easy_pace(athleteId). If still None, default pace=9.0 km/h.\n    - return (duration_sec/3600.0) * pace.\n- Export helpers for UI usage. Do not alter targetLabel strings received from UI.",
            "status": "done",
            "testStrategy": "Unit tests for helpers:\n- resolve_threshold_target returns object only on exact name matches; verify 'Threshold 60/30' returns None.\n- estimate_km: when Fundamental threshold is present, computed using average of min/max; when missing, uses recent_easy_pace; when both missing, defaults to 9.0 km/h.\n- list_threshold_names excludes any 'Threshold 60/30' and includes discrete names."
          },
          {
            "id": 7,
            "title": "Planner page week view (Mon–Sun) with session listing and CRUD hooks",
            "description": "Build the Planner page skeleton: single-athlete week selector, a Monday–Sunday grid showing planned sessions per day, and hooks/buttons for add/edit/delete operations.",
            "dependencies": [
              "4.5"
            ],
            "details": "Implementation steps (pages/Planner.py):\n- Layout:\n  - Athlete selection (single athlete for MVP; allow selecting current athlete from session or settings).\n  - Week selector: show current week by default; provide previous/next week buttons; compute Monday–Sunday dates.\n  - Render a 7-column grid (Mon..Sun). For each day, list planned sessions using PlannedSessionsRepo.list_by_date_range(athleteId, week_start, week_end).\n  - For each row, show: type (FUNDAMENTAL_ENDURANCE, LONG_RUN, INTERVAL_SIMPLE), plannedDistanceKm or plannedDurationSec, targetType/targetLabel, and stepEndMode where relevant.\n  - For FUNDAMENTAL_ENDURANCE, also compute and display estimated km using planner_service.estimate_km.\n- Actions:\n  - Add Session button per day opens an editor by setting st.session_state['planner_edit'] = { 'mode': 'create', 'date': yyyy-mm-dd }.\n  - Edit button on each session sets st.session_state['planner_edit'] = { 'mode': 'edit', 'plannedSessionId': ... }.\n  - Delete button triggers a confirmation; on confirm, repo.delete(plannedSessionId) and rerender.\n- Data I/O:\n  - Ensure reading/writing includes stepsJson and stepEndMode fields; tolerate stepsJson missing/empty via repo from subtask 5.\n- UX:\n  - Keep drag-copy for later (post-MVP); keep layout simple with Streamlit columns and expanders.",
            "status": "done",
            "testStrategy": "Manual UI tests:\n- Navigate weeks; verify sessions appear on correct dates.\n- Add/edit/delete buttons mutate st.session_state as expected; after delete, row disappears and CSV row removed.\n- FUNDAMENTAL rows show estimated km and update when duration changes (wired in subtask 8)."
          },
          {
            "id": 8,
            "title": "Session editor forms for Fundamental Endurance, Long Run, and Simple Intervals with persistence",
            "description": "Implement Streamlit forms to create/edit/delete sessions for all three types. Persist to planned_sessions.csv including stepEndMode and stepsJson for intervals. Enforce discrete threshold names in target labels.",
            "dependencies": [
              "4.5",
              "4.6",
              "4.7"
            ],
            "details": "Implementation steps:\n- Editor modal/panel:\n  - If st.session_state['planner_edit'] is set, render a form tailored to type. Provide a type selector on create; on edit, lock type.\n- FUNDAMENTAL_ENDURANCE form:\n  - Fields: plannedDurationSec (required), optional targetType select ['none','hr','pace']; if hr/pace selected, show targetLabel select populated from planner_service.list_threshold_names (must include 'Threshold 60' and 'Threshold 30' if present) plus allow 'Fundamental'. Optional manual pace field.\n  - Display estimated km dynamically using planner_service.estimate_km(duration, athleteId).\n  - Save: write/update repo row with fields; stepEndMode='', stepsJson=''. Preserve targetLabel verbatim.\n- LONG_RUN form:\n  - Fields: plannedDistanceKm (required), plannedAscentM (optional), plannedDurationSec (optional), targetType optional ['none','hr','pace'] and targetLabel from threshold names (disallow any combined 'Threshold 60/30').\n  - Save: persist values; stepsJson=''; stepEndMode=''.\n- INTERVAL_SIMPLE form:\n  - Fields: warmupSec, cooldownSec, stepEndMode select ['auto','lap'].\n  - Repeats editor: dynamic list of repeat blocks with workSec, recoverSec, targetType in ['hr','pace','sensation'], and targetLabel:\n    - If targetType in ['hr','pace'], targetLabel select from threshold names, preserving discrete names.\n    - If 'sensation', free text input.\n  - Build steps structure: { warmupSec, repeats:[{workSec, recoverSec, targetType, targetLabel}], cooldownSec }.\n  - Save: stepsJson=json.dumps(steps_struct); set stepEndMode accordingly; targetType/targetLabel at row level can be left as empty or the primary target of the work blocks (optional; prefer empty to avoid ambiguity since stepsJson is authoritative).\n- Shared behaviors:\n  - Edit mode: load existing row; parse stepsJson for INTERVAL_SIMPLE and populate form; on save, overwrite row.\n  - Delete: confirm and call repo.delete(plannedSessionId).\n  - All saves must preserve targetLabel exactly as chosen; do not coerce or rename.\n- Validation:\n  - Required fields enforced; numeric seconds/km validated >0.\n  - For hr/pace target types, require targetLabel selection.\n- Post-save: clear st.session_state['planner_edit'] and rerender week view.",
            "status": "done",
            "testStrategy": "Functional tests:\n- Create one session of each type; assert planned_sessions.csv rows include notes, stepEndMode, and stepsJson (interval only) with correct JSON and exact targetLabel strings ('Threshold 60' / 'Threshold 30').\n- Edit existing interval and change stepEndMode; verify CSV updated.\n- Negative tests: selecting 'hr' without targetLabel should block save.\n- Visual check: estimated km displayed for FUNDAMENTAL and matches helper calculation."
          },
          {
            "id": 9,
            "title": "Week templates: save/apply with date shifting and threshold label preservation",
            "description": "Implement templates_service to save a week's plan to templates.csv and apply it to another week, shifting dates. Integrate UI on Planner page. Ensure stepsJson preserves discrete threshold names unchanged.",
            "dependencies": [
              "4.5",
              "4.8"
            ],
            "details": "Implementation steps:\n- templates_service (services/templates_service.py):\n  - save_week_template(athleteId, week_start_date, name):\n    - Fetch sessions in [week_start, week_start+6d].\n    - For each, compute dateOffset = (session.date - week_start).days.\n    - Build a list of dicts with: dateOffset, type, plannedDistanceKm, plannedDurationSec, plannedAscentM, targetType, targetLabel, notes, stepEndMode, stepsJson (string as-is). Do not modify targetLabel; retain exact strings like 'Threshold 60'/'Threshold 30'.\n    - Write a new templates.csv row: templateId=uuid4, athleteId, name, stepsJson=json.dumps(session_list).\n  - list_templates(athleteId): return templates for athlete.\n  - apply_week_template(athleteId, templateId, target_week_start_date):\n    - Load template, parse stepsJson array.\n    - For each item, compute date = target_week_start + timedelta(days=dateOffset).\n    - Create new planned session rows with copied fields and generated plannedSessionId; preserve stepsJson and stepEndMode exactly.\n- Planner UI integration (pages/Planner.py):\n  - Add 'Save current week as template' button with a name input; on click, call save_week_template.\n  - Add a 'Templates' selectbox to choose a template and an 'Apply to this week' button to apply to current week.\n  - After apply, refresh list; optionally warn about duplicates if sessions already exist on those dates.\n- Collision handling:\n  - MVP: allow duplicates; optionally provide a checkbox 'Clear current week before applying' that deletes existing week sessions prior to apply.\n- Documentation/tooltips:\n  - In UI help texts, show examples that explicitly use 'Threshold 60' and 'Threshold 30' and never 'Threshold 60/30'.",
            "status": "pending",
            "testStrategy": "Integration tests:\n- Create a week with all three session types including an INTERVAL_SIMPLE using 'Threshold 60'. Save as template; inspect templates.csv: stepsJson array has correct dateOffset and exact targetLabel strings.\n- Apply template to a different week; verify planned_sessions.csv gains new rows on correct dates with identical stepsJson/stepEndMode and targetLabel strings.\n- If 'clear before apply' is enabled, ensure week is emptied then repopulated."
          },
          {
            "id": 10,
            "title": "Planner backend: repositories, services, and CSV schema migration with discrete threshold names",
            "description": "Implement and wire backend components for the Planner: planned sessions repository with schema migration to add stepsJson and stepEndMode, templates repository, serialization helpers, and planner/templates services. Enforce use of discrete threshold names ('Threshold 60', 'Threshold 30') across target labels, lookups, and examples. Provide helpers for threshold resolution and Fundamental km estimation with fallback.",
            "dependencies": [],
            "details": "Scope:\n- Repositories and migration\n  - planned_sessions_repo.py\n    - Detect and migrate planned_sessions.csv to include columns stepsJson and stepEndMode if missing. Preserve all existing rows and append new empty columns with '' as default values. Preserve column order by appending new columns to the end of the header.\n    - CRUD APIs: list_by_week(athlete_id, week_start_date), upsert(session_dict), delete(session_id).\n    - Ensure exact string preservation for targetLabel and stepsJson across read/write.\n    - Backward-compat: reading a file without stepsJson/stepEndMode should return None for those fields; writing should include both columns (empty string when None).\n  - templates_repo.py\n    - CSV schema: templateId, name, stepsJson. Use compact JSON for stepsJson and preserve all string values exactly.\n    - CRUD: list_all(), get(templateId), save(template_dict), delete(templateId).\n  - Serialization helpers (serialization.py)\n    - serialize_steps(steps: dict|None) -> str: return '' if None else json.dumps(steps, separators=(',', ':'), ensure_ascii=False).\n    - deserialize_steps(s: str) -> dict|None: return None if s in (None, '') else json.loads(s).\n- Services\n  - thresholds_service.py (or extend existing thresholds_repo/service)\n    - list_threshold_names(athlete_id): return names sorted with 'Fundamental' first, then 'Threshold 30', 'Threshold 60', then remaining names alphabetically; explicitly filter out any 'Threshold 60/30' legacy name.\n    - resolve_threshold_target(athlete_id, target_label): return thresholds_repo.find(name==target_label) by exact match; return None for unknown labels, including 'Threshold 60/30'.\n  - planner_service.py\n    - estimate_km(athlete_id, duration_sec): implement as described using Fundamental pace average when available; fallback to recent_easy_pace(athlete_id); default to 9.0 km/h if both missing.\n    - recent_easy_pace(athlete_id): compute median pace (km/h) from up to 4 most recent easy/fundamental activities.\n    - session operations: build_session_dict(...) to normalize fields per type (FUNDAMENTAL_ENDURANCE, LONG_RUN, INTERVAL_SIMPLE); ensure stepEndMode is persisted for INTERVAL_SIMPLE; ensure stepsJson is produced via serialize_steps and matches UI data model:\n      - INTERVAL_SIMPLE steps JSON structure: {\"warmupSec\": int, \"repeats\": [{\"workSec\": int, \"recoverSec\": int, \"targetType\": \"hr\"|\"pace\"|\"sensation\", \"targetLabel\": str}], \"cooldownSec\": int}\n      - stepEndMode: 'auto'|'lap'\n    - list_week(athlete_id, week_start_date), create_or_update_session(session_dict), delete_session(session_id).\n    - All targetLabel strings must be written verbatim (e.g., 'Threshold 60', 'Threshold 30'); never generate or persist 'Threshold 60/30'.\n  - templates_service.py\n    - save_week_template(name, athlete_id, week_start_date): read week sessions; map each to a template item with dateOffset (days from week_start_date), type, planned fields, targetType, targetLabel, stepEndMode, steps (dict). Save one CSV row with stepsJson being a JSON array of these items.\n    - apply_week_template(templateId, athlete_id, target_week_start_date): load template, compute actual dates by adding dateOffset to target_week_start_date, and create sessions via planner_service. Preserve stepsJson, stepEndMode, and targetLabel strings exactly.\n- Discrete threshold names enforcement\n  - Remove any code paths and option lists that produce or accept 'Threshold 60/30'.\n  - Ensure list_threshold_names includes 'Threshold 30' and 'Threshold 60' when present in thresholds_repo and they are selectable downstream.\n- Data contracts and defaults\n  - For FUNDAMENTAL_ENDURANCE: required plannedDurationSec; optional targetType ('hr' or 'pace') + targetLabel; optional plannedPaceKmh; compute estimated_km via estimate_km for display (UI) consumers.\n  - For LONG_RUN: required plannedDistanceKm; optional plannedAscentM; optional plannedDurationSec; optional targetType ('hr'|'pace') + targetLabel.\n  - For INTERVAL_SIMPLE: stepsJson required; stepEndMode required; target labels in repeats must be exact threshold names or free text for 'sensation'.\n  - Default values: treat missing numeric optionals as None; persist '' in CSV.\n- Dev notes\n  - Use pathlib for file paths and csv.DictReader/DictWriter; ensure newline='' when writing.\n  - Generate templateId and sessionId as UUID4 strings if not provided.\n  - Compact JSON is important for deterministic diffs; set separators and sort_keys=False.\n  - All dates as ISO YYYY-MM-DD in CSV.\n",
            "status": "pending",
            "testStrategy": "Repository and service smoke tests (full unit test suite is in Subtask 4.10):\n- Migration: create planned_sessions.csv without stepsJson/stepEndMode; load repo; upsert a row; assert header now includes both columns and existing rows have ''.\n- CRUD: write/read a row for each type; for INTERVAL_SIMPLE include repeats with targetLabel='Threshold 60' and stepEndMode='lap'; assert exact roundtrip string equality.\n- thresholds_service: list_threshold_names excludes 'Threshold 60/30' and orders ['Fundamental', 'Threshold 30', 'Threshold 60', ...]; resolve_threshold_target exact matches and returns None on legacy or unknown.\n- templates_service: save and then apply a template; verify created sessions' fields, stepsJson, stepEndMode, and targetLabel strings are identical to source."
          },
          {
            "id": 11,
            "title": "Planner UI: Streamlit week view with session editor and week templates",
            "description": "Build the Streamlit Planner page with a Mon–Sun calendar grid for a single athlete, forms to add/edit/delete sessions for Fundamental Endurance, Long Run, and Simple Intervals, and buttons to save/apply week templates. Ensure discrete threshold names ('Threshold 60' and 'Threshold 30') are used in all selects and examples, with exact string persistence to CSV.",
            "dependencies": [
              "4.11"
            ],
            "details": "Scope:\n- Week view\n  - Page: pages/planner_page.py. Inputs: athlete selector (single athlete for MVP), week picker (date of any day in target week). Compute week_start_date as Monday and render Mon–Sun columns with date headers.\n  - For each day: list existing planned sessions with compact badges (type, key planned fields, targetLabel). Provide Edit and Delete buttons per row.\n  - Add Session button opens a modal/expander with type selector (FUNDAMENTAL_ENDURANCE, LONG_RUN, INTERVAL_SIMPLE).\n- Session editors\n  - Common: date (fixed to selected day), notes (optional), targetType select ('', 'hr', 'pace', 'sensation' where applicable), targetLabel input/selector depending on targetType.\n  - Threshold target selector: when targetType is 'hr' or 'pace', show a selectbox populated via thresholds_service.list_threshold_names(athlete_id). Do not include 'Threshold 60/30'. Persist selected name verbatim to targetLabel.\n  - FUNDAMENTAL_ENDURANCE form:\n    - plannedDurationSec (required, number input), optional pace (plannedPaceKmh) and optional HR cap via targetType='hr' + targetLabel from thresholds select.\n    - Show estimated_km = planner_service.estimate_km(athlete_id, plannedDurationSec) with hint text indicating source (Fundamental threshold avg or recent easy-run median fallback).\n  - LONG_RUN form:\n    - plannedDistanceKm (required), plannedAscentM (optional), plannedDurationSec (optional), optional threshold target via targetType ('hr'/'pace') + targetLabel select (explicitly 'Threshold 60' or 'Threshold 30' when present).\n  - INTERVAL_SIMPLE builder:\n    - warmupSec (required), repeats editor (number of repeats, then dynamic rows each with workSec, recoverSec, targetType radio ['hr','pace','sensation'] and targetLabel: select for hr/pace from thresholds list, free-text for sensation), cooldownSec (required), stepEndMode select ['auto','lap'].\n    - Render a compact preview of steps JSON for confirmation before saving.\n- Actions\n  - Save: Build a session_dict matching backend contract and call planner_service.create_or_update_session(). Ensure stepsJson (from builder dict) and stepEndMode persist for INTERVAL_SIMPLE.\n  - Delete: Confirm then call planner_service.delete_session(session_id).\n  - Validation: enforce required fields per type; show inline errors; prevent save if invalid.\n- Week templates\n  - Save current week as template: name input, then call templates_service.save_week_template(name, athlete_id, week_start_date). Show success with templateId.\n  - Apply template: dropdown of templates_repo.list_all(); select target week (defaults to current); apply via templates_service.apply_week_template(templateId, athlete_id, target_week_start_date). Refresh view.\n- Discrete threshold names and copy rules\n  - All UI labels, examples, and placeholders must reference 'Threshold 60' and 'Threshold 30' explicitly. Ensure no occurrences of 'Threshold 60/30'.\n  - When editing existing sessions/intervals, load targetLabel exactly and re-select the matching threshold; if not found, show it as read-only free-text with a warning.\n- UX details\n  - Keep forms compact and type-specific. Use st.form to batch validation and submission. Use st.experimental_rerun after mutations to refresh the grid.\n  - Date formatting ISO (YYYY-MM-DD) and times in seconds fields with helper hints (e.g., 'mm:ss' parsing optional in future).\n",
            "status": "pending",
            "testStrategy": "Manual and smoke testing:\n- Create, edit, and delete each session type across a week; confirm rows in planned_sessions.csv include stepEndMode for intervals and stepsJson with exact targetLabel strings ('Threshold 60'/'Threshold 30').\n- Verify the Fundamental estimate updates when changing plannedDurationSec and after modifying thresholds data (reload page).\n- Ensure the threshold selector contains 'Fundamental', 'Threshold 30', 'Threshold 60' and never 'Threshold 60/30'.\n- Save a week template with a mix of types (including an interval); apply it to another week; confirm sessions render correctly and CSV persists identical stepsJson/stepEndMode/targetLabel values.\n- Edge: interval with targetType='sensation' preserves free-text label; long run with only ascent set remains valid with distance present; editing legacy sessions without stepsJson shows blank steps and allows adding steps."
          }
        ]
      },
      {
        "id": 5,
        "title": "Strava OAuth2 integration and 14-day manual sync with timeseries",
        "description": "Implement Strava OAuth authorization code flow, token refresh, and manual sync to import last 14 days of activities including detail and timeseries streams. Store raw JSON and normalized CSV rows.",
        "details": "OAuth:\n- Authorization URL: https://www.strava.com/oauth/authorize?client_id=...&response_type=code&redirect_uri={STRAVA_REDIRECT_URI}&scope=activity:read,activity:read_all&state=random\n- Token exchange: POST https://www.strava.com/api/v3/oauth/token with grant_type=authorization_code; refresh with grant_type=refresh_token\n- Save encrypted tokens to tokens.csv (provider='strava')\nSync logic (services/strava_service.py):\n- list_activities(after_ts): GET /api/v3/athlete/activities?after={unix_ts}&per_page=200&page=n; paginate until empty\n- For each activity id, GET /api/v3/activities/{id} for details (splits/laps)\n- Streams: GET /api/v3/activities/{id}/streams?keys=time,distance,altitude,heartrate,cadence,latlng,velocity_smooth&key_by_type=true\n- Map to activities.csv columns; compute movingSec if available; polyline from summary_polyline; rawJsonPath='data/raw/strava/{id}.json'\n- Timeseries save: build DataFrame with timestamp (epoch or ISO), hr, paceKmh=velocity_smooth*3.6, elevationM=altitude, cadence, lat, lon; write to data/timeseries/{id}.csv; set hasTimeseries=true\n- Only list unlinked in Activities page: join to links.csv and filter where activityId not present\nToken refresh:\n- Before API calls, if now>=expiresAt-300s, refresh; update tokens.csv\nPseudocode:\n  def sync_last_14_days(athlete_id):\n      after=int((now-14d).timestamp())\n      acts=list_activities(after)\n      for a in acts:\n         if not activities_repo.exists(a['id']):\n            detail=get_activity(a['id']); save_raw(detail)\n            ts=get_streams(a['id']); save_timeseries(ts)\n            row=map_to_row(detail)\n            activities_repo.create(row)\n",
        "testStrategy": "- Use a test Strava app; perform OAuth locally; verify tokens saved encrypted and refresh works.\n- Mock requests (responses library) to test pagination and mapping to CSV; assert activities.csv populated and timeseries files created.\n- Validate only last 14 days are fetched; ensure unlinked filter in Activities page works.\n- Error handling: simulate 429 rate limit; implement backoff and resume.",
        "priority": "medium",
        "dependencies": [],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 6,
        "title": "Garmin import via python-garminconnect and manual FIT/TCX ingest",
        "description": "Add Garmin data ingest using garminconnect for last 14 days and a manual wizard for FIT/TCX uploads to populate activities and timeseries.",
        "details": "Garmin Connect import (services/garmin_import_service.py):\n- Library: garminconnect (cyberjunky/python-garminconnect)\n- Flow:\n  - Prompt user on Activities page to enter Garmin email/password (use st.text_input with type='password'); do not store password\n  - from garminconnect import Garmin; client = Garmin(email, password); client.login(); handle MFA if configured (client requires 2FA code; prompt and call client.login(mfa_code))\n  - activities = client.get_activities(0, 100); filter by startTime in last 14 days\n  - For each activity: get details/time series\n    - summary = client.get_activity_summary(activity_id)\n    - samples = client.get_activity_details(activity_id) or client.get_activity_tcx(activity_id) if available\n  - Map to activities.csv columns; source='garmin'; startTime ISO; compute distanceKm, elapsedSec, movingSec, ascentM, avgHr, maxHr; hasTimeseries=True if samples present\n  - Save timeseries: build columns timestamp, hr, paceKmh (from speed m/s*3.6), elevationM, cadence, lat, lon (if provided)\nManual FIT/TCX ingest:\n- UI: st.file_uploader(accept=['.fit','.tcx']) and associate with athlete\n- FIT parsing: fitparse library; iterate records to extract timestamp, heart_rate, speed, altitude, cadence, position_lat/lng; convert semicircles to degrees\n- TCX parsing: lxml; parse Trackpoint for Time, HeartRateBpm, DistanceMeters (diff to speed), AltitudeMeters, Cadence, Position\n- Create Activity row with source='manual'; allow user to edit distance/time before saving\n- Save timeseries to data/timeseries/{activityId}.csv\nPseudocode:\n  def import_garmin_last_14d(athlete_id):\n      client=Garmin(email, password); client.login(); acts=client.get_activities(0,100)\n      for a in acts: if within_14d(a['startTimeLocal']): save_activity(a)\n",
        "testStrategy": "- Mock garminconnect client in unit tests; simulate activities list and details; verify mapping and CSV writes.\n- FIT/TCX parser tests with sample files; assert timeseries rows and computed paceKmh correctness.\n- Manual UI test: upload TCX and confirm activity appears as unlinked.\n- Error paths: invalid credentials, MFA required, network errors handled with user-friendly messages.",
        "priority": "medium",
        "dependencies": [],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 7,
        "title": "Activities page: details view, linking workflow, suggestions, and RPE capture",
        "description": "Provide Activities page to review synced/ingested activities, view details (splits/elevation/timeseries), link to planned sessions with suggested matches, and record RPE (1–10) and comments.",
        "details": "Linking logic (services/linking_service.py):\n- Suggestion heuristic matchScore in [0,1]:\n  score = 0.4*(1 - min(|dist_diff|/max(plannedDistanceKm,1),1)) + 0.4*(1 - min(|dur_diff|/max(plannedDurationSec,1),1)) + 0.2*(1 - min(|date_diff_days|/2,1))\n- Consider type compatibility: add +0.1 bonus if both interval vs non-interval align; cap at 1.0\n- For fundamental/long runs missing targets, rely on duration/distance\n- Provide API: suggest_links(athlete_id, window_days=7) -> list of (activityId, plannedSessionId, score)\nActivities page UI:\n- Tabs: Unlinked | Linked\n- Unlinked: list last 14 days activities not in links.csv; show Strava/Garmin source icon\n- On select activity: show details panel with summary + charts (Altair): pace/hr over time, elevation profile; splits if available\n- Suggest matches sorted by score; allow manual override via dropdown of planned sessions on same week\n- Link form: choose plannedSessionId, enter RPE slider 1–10, comments; on save, write links.csv with linkId and matchScore\n- Edit/delete link; RPE editable post-save\n- Only activities not yet linked appear in default list\nData use:\n- Read activities.csv, planned_sessions.csv, links.csv; join to show statuses\nPseudocode:\n  def create_link(activity_id, planned_id, rpe, comments):\n      score = compute_score(activity_id, planned_id)\n      links_repo.create({linkId: uuid(), plannedSessionId: planned_id, activityId: activity_id, matchScore: score, rpe: rpe, comments: comments})\n",
        "testStrategy": "- Unit tests for compute_score with edge cases: perfect match (score≈1), date off by 3 days (penalized), missing planned distance/duration.\n- Integration test: create planned + import dummy activity; link and verify links.csv entry; ensure activity removed from Unlinked list.\n- UI manual test: enter RPE and comments, edit link, delete link.\n- Visualization sanity: charts render when timeseries exists; fall back gracefully if missing.",
        "priority": "medium",
        "dependencies": [],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 8,
        "title": "Goals & Races page and data model",
        "description": "Implement CRUD for goals (races) and simple progress-to-goal views. Ensure races are counted as intense in downstream analytics.",
        "details": "Data:\n- goals.csv per PRD columns plus isRace=true for all MVP entries\nUI:\n- Goals page: list goals; add/edit form with date, distanceKm, ascentM, terrain, priority (A/B/C), targetTimeSec\n- Progress-to-goal: show countdown (days until race), planned key sessions upcoming, cumulative weekly distanceEq vs time until race; badge for priority\nIntegration with analytics:\n- Expose helper: analytics_service.is_race_day(date)->True if goal for athlete on that date\n- When aggregating, activities occurring on goal date are treated as intense\nPlanner integration (optional MVP utility):\n- Button to create a planned session of type 'RACE' on goal date with planned distance/ascent\nPseudocode:\n  def add_goal(goal): goals_repo.create({goalId: uuid(), ... , isRace: True})\n  def upcoming_goals(athlete_id): return goals_repo.list(filter by date>=today)\n",
        "testStrategy": "- CRUD tests for goals_repo; ensure CSV updates persist.\n- UI test: create a race; verify it appears and countdown is correct.\n- Analytics integration test: activity on goal date contributes to intense time in metrics (validated in task 9).\n- Edge cases: multiple goals in a week; overlapping races — both flagged.",
        "priority": "medium",
        "dependencies": [],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 9,
        "title": "Analytics service, weekly aggregates, and dashboards",
        "description": "Compute weekly planned vs actual aggregates and intense vs easy classification into metrics.csv. Build Dashboard and Analytics pages with charts and KPIs.",
        "details": "Computation (services/analytics_service.py):\n- distanceEqKm = distanceKm + ascentM * distanceEqFactor (coach configurable; default 0.01)\n- Weekly aggregation period: ISO week (Mon–Sun) using utils/time.py\n- Classify Intense vs Easy:\n  - Intense: interval work steps time from linked planned sessions of type INTERVAL_SIMPLE (sum workSec only), and races (activity on goal date)\n  - Easy: recovery steps, fundamental, long runs\n  - If HR/pace missing, rely on session type/step type; if activity unlinked, default to Easy unless date==race day\n- Planned vs Actual KPIs per week: timeSec (sum plannedDurationSec vs sum movingSec), distanceKm (plannedDistanceKm vs distanceKm), distanceEqKm, intenseTimeSec, easyTimeSec, numSessions, adherencePct = (#linked planned sessions / #planned sessions)*100\n- Write metrics.csv with one row per week per athlete\nPages:\n- Dashboard: alerts (unlinked activities count, missed sessions where planned has no link and date < today), weekly snapshot tiles, upcoming key sessions (long run, intervals, races)\n- Analytics: Altair/Plotly charts:\n  - Stacked bar planned vs actual by week for time/distance/distanceEq\n  - Pie chart of intense vs easy time for selected week\n  - Filters: week range, athlete\nPseudocode:\n  def compute_weekly_metrics(athlete_id):\n      weeks = group_by_week(activities, planned, links)\n      for week in weeks:\n          calc planned sums, actual sums; classify intense/easy; write row\n",
        "testStrategy": "- Unit tests: classification function with synthetic planned intervals and races; verify only work steps counted as intense.\n- Aggregation tests: known inputs produce exact metrics.csv row values; adherencePct correct with partial linking.\n- UI tests: charts render; filter changes recompute and update views.\n- Edge cases: missing plannedDistanceKm or plannedDurationSec should not break; default to 0 for planned where missing.",
        "priority": "medium",
        "dependencies": [],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 10,
        "title": "Garmin TCX export for interval workouts",
        "description": "Implement export of planned INTERVAL_SIMPLE workouts to TCX files with per-step auto (time-based) or manual (lap) end modes and target encoding. Provide download UI.",
        "details": "Exporter (services/garmin_export_service.py):\n- Input: planned session with steps structure and stepEndMode (auto|lap)\n- Mapping:\n  - Auto end: use Time duration for step (<Duration><Time>seconds</Time></Duration>)\n  - Lap/manual end: create Open steps (no duration) so user presses Lap to advance\n  - Targets:\n    - HR: include Notes with targetLabel (since precise HR zones mapping to Garmin zones is out-of-scope for MVP)\n    - Pace: include Notes with pace target text\n    - Sensation: free-run with Notes=targetLabel\n- TCX structure: TrainingCenterDatabase > Workouts > Workout (Name) > Steps (Step number, Name, Duration, Intensity, Notes)\n- Build XML with xml.etree.ElementTree; pretty-print\n- Filename: workout_{plannedSessionId}.tcx\nUI (Activities page or Planner):\n- List interval planned sessions; select one; st.download_button to get TCX\nPseudocode:\n  def to_tcx(planned):\n      root=Element('TrainingCenterDatabase', xmlns='http://www.garmin.com/xmlschemas/TrainingCenterDatabase/v2')\n      w=SubElement(root,'Workouts'); wk=SubElement(w,'Workout');\n      for i,step in enumerate(steps):\n          s=SubElement(wk,'Step'); SubElement(s,'StepId').text=str(i+1)\n          if stepEndMode=='auto': add Time duration\n          else: add Open duration (manual)\n          SubElement(s,'Notes').text=step['targetLabel'] or ''\n      return tostring(root)\nValidation:\n- Ensure only INTERVAL_SIMPLE sessions export; warn otherwise\n",
        "testStrategy": "- Unit tests: generate TCX from a sample interval session; assert XML contains correct number of steps and duration mapping for auto vs lap.\n- Manual validation: import TCX into Garmin Connect or compatible tool; verify step advancement behavior.\n- Error handling: exporting non-interval sessions should show a clear message; invalid steps JSON handled gracefully.",
        "priority": "medium",
        "dependencies": [],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 11,
        "title": "Pytest test suite for scaffolding/config/FR formatting and CSV storage/repositories",
        "description": "Add a comprehensive pytest suite covering config/environment wiring, FR locale formatting utilities, time/ids helpers, CSV storage, and repositories. Ensure all tests isolate filesystem state using tmp_path and monkeypatch so nothing writes to the real data folder.",
        "details": "Scope and goals:\n- Provide unit tests for components introduced by Task 1: utils/formatting.py, utils/time.py, utils/ids.py, persistence/csv_storage.py, and persistence/repositories.py.\n- Verify environment/config wiring (DATA_DIR resolution and creation) without touching the real filesystem.\n- Enforce FR-locale output conventions (decimal comma, thin non‑breaking space for thousands) while keeping tests robust if OS locale is unavailable.\n\nTest layout (under tests/):\n- tests/conftest.py: shared fixtures and helpers\n- tests/test_config.py: environment and default data dir behavior\n- tests/utils/test_formatting.py: FR locale formatting utilities\n- tests/utils/test_time_ids.py: time helpers and id generation\n- tests/persistence/test_csv_storage.py: low-level CSV read/write behaviors\n- tests/persistence/test_repositories.py: repository CRUD, id generation, and persistence\n\nFixtures and helpers (tests/conftest.py):\n- Fixture tmp_data_dir(tmp_path): returns a fresh directory path per test.\n- Fixture env_data_dir(monkeypatch, tmp_data_dir): monkeypatches os.environ[\"DATA_DIR\"] to tmp_data_dir and yields the path.\n- Fixture reload_storage(monkeypatch): helper to importlib.reload persistence.csv_storage and persistence.repositories after setting env to ensure module-level constants read patched env.\n  - Usage pattern in tests: set env -> reload csv_storage -> reload repositories -> run assertions.\n- Fixture fr_locale_available(): attempts to activate fr_FR (e.g., fr_FR.UTF-8) or checks formatting module’s fallback flags. If unavailable, marks locale-sensitive tests as skipped with a clear reason.\n- Helper assert_no_real_data_writes(tmp_project_root): after a test run, assert that known real data folders (e.g., ./data or value from default) were not created or modified. Use os.path.exists checks guarded by CWD control (see below).\n- Optional fixture cwd_to_tmp(monkeypatch, tmp_path): chdir to a temp project root to avoid accidental relative writes if modules default to ./data when DATA_DIR is absent.\n\nFile-specific guidance and key cases:\n1) tests/test_config.py\n- Goal: validate that modules compute DATA_DIR from env and create it lazily/safely, never touching the real project folder.\n- Cases:\n  - When DATA_DIR is set to tmp path before importing csv_storage, get_data_dir() (or equivalent) returns that path and create_data_dir() creates it if missing.\n  - When DATA_DIR is unset, module should default to ./data but ONLY when explicitly invoked. Use cwd_to_tmp to ensure any default write happens under a temp CWD, not the repo.\n  - .env handling: monkeypatch dotenv values via monkeypatch.setenv and reload module; verify precedence: explicit env > .env > default.\n  - Idempotence: calling ensure_data_dir() repeatedly causes no error and does not change permissions unexpectedly.\n\n2) tests/utils/test_formatting.py\n- Validate FR locale display utilities:\n  - Numbers: 1234.5 -> '1 234,5' (thin non‑breaking space U+202F) and decimal comma.\n  - Distances/speeds: format_distance_km(0) == '0,0 km'; format_distance_km(1234.5) includes thousands grouping; format_speed_kmh(12.345) rounds as specified by the module (e.g., 12,35 km/h).\n  - Durations: format_duration_sec(300) -> '5:00' or '5:00 min' per spec; verify zero-padding.\n  - Dates: format_date for a known date outputs FR month/day order and names if implemented.\n- Robustness:\n  - If the implementation falls back when fr_FR locale is not installed, assert that the fallback still uses ',' as decimal and inserts a non-breaking space for thousands. Otherwise mark skip via fr_locale_available.\n\n3) tests/utils/test_time_ids.py\n- ids:\n  - new_id()/uuid4 wrapper returns a valid UUID4 string; regex match and version check; generate 1000 ids and assert uniqueness.\n- time:\n  - ISO week computations: ensure monday_of_week(date) returns Monday; boundary cases around year edges (e.g., 2019-12-30, 2020-01-01, 2021-01-03, 2021-01-04).\n  - Week number and year: iso_week_key(date) returns tuples/strings consistent with ISO 8601 (e.g., (2020,1)).\n  - Parsing/formatting helpers (if present): roundtrip a date string.\n\n4) tests/persistence/test_csv_storage.py\n- With env_data_dir + reload_storage in place:\n  - write_csv('activities.csv', rows, headers) creates the file under tmp DATA_DIR with headers once; read_csv returns rows as dicts with proper types or strings per module contract.\n  - Append/overwrite behavior: test that subsequent writes do not duplicate headers and either overwrite or append according to the module API; cover both code paths if provided (e.g., save_all vs append_row).\n  - Atomic write (if implemented): when write uses temp file + rename, simulate interruption by writing large content and ensuring final file exists and is complete. Minimal assertion: file content equals expected rows; file is not partially written.\n  - File creation: read_csv on missing file returns [] (or raises a well-defined error). Test both behaviors and document expectation in assertion message.\n\n5) tests/persistence/test_repositories.py\n- Instantiate repository instances using tmp DATA_DIR (via env_data_dir + reload_storage + reload repositories).\n- CRUD:\n  - add(entity_without_id) assigns a UUID4 id; entity_with_id preserves provided id; data persists to CSV.\n  - get_by_id returns the entity; list_all returns correct count; filter_by(predicate) or list_by_field returns expected subset.\n  - update(id, changes) persists modifications; delete(id) removes the row; operations survive re-instantiation (fresh Repository reading from file).\n- Concurrency-light safety: calling add/update/delete in quick succession does not corrupt the CSV (validate final row count and contents).\n- Header integrity: first line contains expected columns; missing optional fields are blank but columns remain consistent across writes.\n\nGeneral implementation notes:\n- Always set env_data_dir before importing csv_storage/repositories in each test module; then reload those modules to pick up the patched env.\n- Never reference the project’s real ./data; use cwd_to_tmp for tests that involve defaults.\n- Prefer pathlib.Path operations and tmp_path for file IO.\n- Keep test data minimal and explicit to avoid locale/timezone flakiness; for dates, use datetime.date with explicit values.\n- Add pytest.ini with:\n  - testpaths = tests\n  - addopts = -ra -q --strict-markers --maxfail=1\n  - markers: locale, storage\n- Optional: .coveragerc and a minimal CI command example (pytest --cov=.\n\nExample patterns to use in tests (inline snippets):\n- Set DATA_DIR and reload:\n  monkeypatch.setenv(\"DATA_DIR\", str(tmp_data_dir))\n  import importlib, persistence.csv_storage as cs\n  importlib.reload(cs)\n- Skip if FR locale unavailable:\n  pytest.skip(\"fr_FR locale unavailable; skipping strict locale rendering tests\")\n- Assert thin non‑breaking space:\n  assert \"\\u202f\" in s or \"\\xa0\" in s\n\nDeliverables:\n- All test files as listed, with clear, deterministic assertions.\n- pytest.ini and, if desired, a minimal .coveragerc.\n- No modifications to production code except adding any minimal test hooks if absolutely necessary (prefer reloading over code changes).\n",
        "testStrategy": "Execution:\n- Prepare a clean working tree. Ensure no ./data folder exists prior to running tests.\n- Run: pytest -q (or pytest -q --maxfail=1) from repo root.\n\nAcceptance checks by area:\n- Config/env:\n  - Tests pass proving env-driven DATA_DIR is respected; default-only code paths are exercised under a temporary CWD; no writes occur outside tmp dirs.\n- Formatting:\n  - Decimal comma and thousands separator verified for representative values; duration zero-padding and rounding confirmed; tests are skipped gracefully if strict FR locale is unavailable and no fallback is implemented.\n- Time/IDs:\n  - UUID4 regex and version pass; 1k generated IDs are unique; ISO week edge cases correct for at least four boundary dates.\n- CSV storage:\n  - Read/write roundtrip produces exact rows; headers are correct; missing-file read behavior conforms to expectation (either [] or defined exception captured and asserted); no partial files are created.\n- Repositories:\n  - Full CRUD persists across instance reload; add auto-generates id; update and delete results are reflected in CSV; list and filter return correct results.\n\nSafety/invariants:\n- After the test run, verify that no real data directory was created or modified (assert not os.path.exists(repo_root/\"data\")).\n- All filesystem writes are contained under pytest tmp_path directories.\n\nCoverage goal:\n- Aim for >80% coverage across utils/ and persistence/ modules introduced in Task 1.\n\nManual verification (optional):\n- Temporarily unset DATA_DIR and run pytest; ensure tests that rely on defaults use cwd_to_tmp and still avoid touching repo root.\n",
        "status": "done",
        "dependencies": [
          1
        ],
        "priority": "medium",
        "subtasks": []
      },
      {
        "id": 12,
        "title": "Planner UI polish: session cards, icon actions, and session details page with navigation",
        "description": "Revamp the Planner week view to render sessions as cards with icon-only actions and a details view, then polish visuals and performance. First slice shipped: week view now uses icon-only actions (⚙️ edit, 🗑️ delete, 🔎 view) and renders sessions as simple cards showing type, duration, distance (if set), target (type/label), and end mode when present. A new details page exists at pages/Session.py with an overview and an interval steps JSON preview; Back/Edit actions navigate via page links. Next: improve card visual styling and add compact badges; add an empty-state placeholder; and consider caching/memoization for faster refreshes. Align labels with Task 4 storage; do not change storage format.",
        "status": "done",
        "dependencies": [
          4
        ],
        "priority": "medium",
        "details": "Current state (first slice implemented)\n- Planner week view\n  - Text action buttons replaced with icon-only actions: ⚙️ (Edit), 🗑️ (Delete), 🔎 (View)\n  - Sessions render in simple card containers showing: type, duration, distance if set, target (type/label) and end mode when present\n  - Delete includes confirmation before removal; data reloaded after deletion\n- Session details\n  - New page at pages/Session.py\n  - Shows session overview and interval steps JSON preview\n  - Back and Edit actions navigate via page links back to Planner and into editor\n\nWhat remains / next increments\n- Visual polish: improve card styling (border, padding), align icon column, and add compact badges (e.g., type, target kind, end mode)\n- Empty state: when a day/week has no sessions, show a helpful placeholder and CTA to add a session\n- Details rendering: replace JSON preview with a readable list/table of steps for INTERVAL_SIMPLE, including durations, end modes (auto vs lap), and target labels; ensure sections are hidden when no data\n- Navigation consistency: prefer page links for details navigation; optionally support sid via st.session_state or query params for deep linking and resilience; ensure Back/Edit flows remain clear\n- Performance: add caching/memoization (e.g., st.cache_data) for repository reads and summary computations; invalidate appropriately on edit/delete to reduce rerender time\n\nScope and constraints\n- Alignment with Task 4: storage format unchanged (planned_sessions.csv with stepsJson, stepEndMode, target fields and labels such as 'Threshold 60'/'Threshold 30')\n- UI-only and lightweight helpers allowed (e.g., formatting/summarization for cards and details)\n- Keep labels exactly as stored; do not introduce new naming\n\nImplementation plan (updated)\n1) Card visual polish and badges\n- Use st.container/st.columns and subtle CSS via st.markdown to add borders, padding, and hover affordance\n- Add small badges for session type (e.g., FUNDAMENTAL, LONG), target kind (HR/Pace), and end mode (auto/lap for intervals)\n- Keep icon buttons compact with tooltips; maintain accessibility via clear text on the main line\n\n2) Empty state\n- When no sessions exist for a day (or week), show a placeholder with a short hint and an Add Session CTA that opens the editor\n\n3) Details page enhancements (pages/Session.py)\n- Replace JSON preview with a readable list/table of steps for INTERVAL_SIMPLE, showing duration, end mode, and any per-step target label\n- Show estimates (e.g., ≈ km) if available from Task 4 logic; hide sections when data is absent\n- Maintain Back and Edit page-link actions; add optional Delete with confirmation that navigates back to Planner after success\n\n4) Navigation consistency\n- Continue using page links (🔎) to open details; ensure a stable way to identify the selected session (e.g., via session_state sid or query param)\n- On Back/Edit from details, navigate via page links and ensure the planner editor can pre-open using st.session_state['planner_edit_sid']\n- If both page-link and session_state approaches are supported, prefer page links and keep session_state as a fallback for deep links or refreshes\n\n5) Performance and caching\n- Cache repository reads and derived summaries with st.cache_data or equivalent\n- Invalidate caches after edit/delete operations; re-query and re-render the week view\n- Consider debouncing rapid reruns after actions\n\n6) Helper utilities (ui/components.py)\n- format_duration(sec) -> mm:ss or h:mm:ss\n- summarize_targets(session) -> compact string for FUNDAMENTAL/LONG (HR cap label, pace, ≈km if available) and INTERVAL_SIMPLE (repeat/work/rec summary with end mode and primary target label)\n\nEdge cases\n- Details opened directly without a resolvable session: show a friendly message with a Back link to Planner\n- Sessions with missing optional fields: do not show empty sections or placeholder text\n- Concurrent modifications: after edit or delete, ensure Planner re-reads data and refreshes the view\n\nExample snippets (illustrative)\n- View action (Planner): a 🔎 page link to pages/Session.py associated with the selected session; set or infer sid so details can load the correct item\n- Back/Edit (Details): page links back to pages/Planner.py; for Edit, set planner_edit_sid to pre-open the editor; ensure data refresh after save/delete",
        "testStrategy": "Manual UI verification (current and upcoming polish)\n1) Pre-setup: Using Planner from Task 4, create at least three sessions in a week: FUNDAMENTAL_ENDURANCE (with HR cap targetLabel='Threshold 60'), LONG_RUN (no targets), and INTERVAL_SIMPLE (with steps and mixed stepEndMode)\n2) Week view cards (current):\n- Each session renders as a card with type and duration visible; distance shown if set; target label and end mode shown only when present; no placeholder text for missing fields\n- Icon actions present: ⚙️ (with help tooltip 'Edit session'), 🗑️ ('Delete session' with confirmation), 🔎 ('View details')\n3) Navigation to details:\n- Clicking 🔎 opens pages/Session.py; verify the selected session loads correctly\n- Back and Edit from details return to Planner and open the editor respectively; confirm edits are applied and the card updates after save\n4) Details page content (current):\n- Overview displays type, date (if available), and duration; interval sessions show steps JSON preview\n- Target labels render exactly as stored (e.g., 'Threshold 60', 'Threshold 30'); no empty sections\n5) Visual polish (after implementation):\n- Cards show subtle border/padding and compact badges (type/target/end mode); icons are aligned in a compact column; tooltips present\n6) Empty state (after implementation):\n- With no sessions for a given day/week, a clear placeholder appears with an Add Session CTA that opens the editor\n7) Enhanced details rendering (after implementation):\n- Interval session steps render as a readable list/table with durations, end modes (auto vs lap), and per-step target labels when present; estimates shown if available\n8) Delete flow:\n- From Planner, click 🗑️; confirm a delete confirmation is required and that after confirming, the card disappears and the underlying CSV/repo reflects the deletion; details page for a deleted sid shows a friendly not-found message with Back\n9) Performance/caching (after implementation):\n- With caching enabled, observe faster refresh after navigations; verify cache invalidates after edit/delete and week view reflects latest data\n\nOptional unit-level checks\n- Unit test format_duration and summarize_targets with representative inputs\n- If a state/query mechanism is used for details navigation, unit test the resolver that extracts the active sid",
        "subtasks": [
          {
            "id": 1,
            "title": "Polish card visuals and add compact badges",
            "description": "Add bordered/padded card styling using st.container/st.markdown CSS, align icon column, and display compact badges for type, target kind, and end mode.",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "Empty-state placeholder for days/weeks without sessions",
            "description": "Render a friendly empty-state with guidance and an Add Session CTA when no sessions exist for a day/week.",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "Enhance details page rendering for intervals",
            "description": "Replace steps JSON preview with a readable list/table of steps including duration, end mode (auto/lap), and any target labels; hide empty sections; show estimates if available.",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "Unify navigation and selection handling",
            "description": "Use page links for 🔎 view and ensure the selected session is reliably identified (via session_state or query param). Implement Back/Edit flows accordingly; keep planner_edit_sid pre-open behavior.",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 5,
            "title": "Add caching/memoization with proper invalidation",
            "description": "Cache repository reads and summary computations with st.cache_data; invalidate caches on edit/delete; ensure Planner re-queries and re-renders fresh data.",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 6,
            "title": "Finalize helper utilities and tests",
            "description": "Implement/finish format_duration and summarize_targets in ui/components.py and add unit tests covering typical sessions (Fundamental/Long/Interval).",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 7,
            "title": "QA manual pass and fixes",
            "description": "Run through the updated test plan, capture regressions (navigation, tooltips, badges, empty-state), and apply fixes before closing the task.",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 13,
        "title": "Planner week view: wider layout, estimated km on cards/details, and weekly totals under grid",
        "description": "Widen the Planner week layout, display estimated kilometers for each planned session on both cards and the session details page, and show weekly totals (time, distance, ascent) below the grid. Use PlannerService for all estimates and do not change the CSV schema.",
        "details": "Scope and goals\n- UI: Wider week grid, session cards display estimated km, session details page displays estimated km, and a weekly totals bar (time, distance, ascent) under the week grid.\n- Logic: Centralize all distance estimation and totals computation in PlannerService. No changes to CSV schemas or persisted values; estimates are computed on-the-fly.\n\nNon-goals\n- No changes to metrics.csv or analytics computations (Task 9). No edits to planned_sessions.csv schema; do not persist estimated distances.\n\nPlannerService (services/planner_service.py)\n- Add or extend a dedicated service to compute per-session distance estimates and weekly totals. Suggested API:\n  - estimate_distance_km(planned_session: dict, athlete_ctx: dict) -> float | None\n    - Inputs:\n      - planned_session: object/dict from repositories (matches current CSV-backed schema and Task 4 storage conventions)\n      - athlete_ctx: includes thresholds and recent easy-run pace fallback, e.g., {\n          \"thresholds\": {\"fundamental\": pace_s_per_km, ...},\n          \"recent_easy_pace_s_per_km\": float | None\n        }\n    - Behavior:\n      - If planned_session has plannedDistanceKm, return it as the primary distance for display when we explicitly show planned distance; still compute and return an estimate when requested for display as \"Est.\" (UI decides whether to show both or only the estimate when planned distance is missing).\n      - If no plannedDistanceKm and plannedDurationSec exists:\n        - FUNDAMENTAL_ENDURANCE and LONG_RUN: estimate = plannedDurationSec / pace_s_per_km, using thresholds[\"fundamental\"]. If missing, fallback to recent_easy_pace_s_per_km. If both missing, return None.\n        - INTERVAL_SIMPLE:\n          - If session-level plannedDurationSec exists, use fundamental or recent easy pace as above.\n          - Else, if steps exist: sum only steps with stepEndMode=='auto' and known durations, estimate per-step distance using any explicit pace targets if available; otherwise use fundamental/recent easy. Ignore 'lap' steps with no duration. If no usable durations, return None.\n      - Round to 0.1 km for card and totals display; return raw float before rounding so UI can format.\n      - Never mutate sessions or write to CSV.\n  - weekly_totals(sessions: list[dict], athlete_ctx: dict) -> dict\n    - Returns: {\n        \"timeSec\": int,                          # sum of plannedDurationSec (ignore None)\n        \"distanceKm\": float,                     # sum of distance using: plannedDistanceKm if present else estimated distance\n        \"ascentM\": int,                          # sum of plannedAscentM when present\n        \"distancePlannedOnlyKm\": float,          # sum of plannedDistanceKm only (for tooltip/secondary display)\n        \"distanceEstimatedOnlyKm\": float         # sum of estimates only for sessions lacking planned distance\n      }\n    - Use estimate_distance_km as needed. Treat missing values as 0 for sums. Memoize by week key + sessions version to avoid recomputes.\n\nUI changes\n- Wider layout (week grid):\n  - Increase container max-width and allow responsive behavior:\n    - Set grid container to max-width ~1400–1600px on desktop; allow horizontal scroll below 1024px if necessary.\n    - Ensure day columns remain equal widths; keep card height autosizing to content.\n  - Verify icon-only actions from Task 12 remain aligned and visible at wider widths.\n- Session cards (week view):\n  - Display estimated distance as a compact badge or line:\n    - If plannedDistanceKm present: show \"Dist: X.X km\" and \"Est: Y.Y km\" as a subdued badge (only if estimate differs by ≥0.1 km; otherwise omit Est to reduce noise).\n    - If no plannedDistanceKm: show \"Est: Y.Y km\" prominently after duration.\n  - Use utils/formatting for FR locale: one decimal for km; thin non-breaking space for thousands not needed for km but apply standard formatter for consistency.\n- Session details page (pages/Session.py):\n  - Add an \"Estimated distance\" field below duration/distance. Show both planned distance (if set) and estimated distance, with a short help text: \"Estimate is computed from thresholds or recent easy pace. Not saved to CSV.\" \n- Weekly totals bar (under grid):\n  - Fixed row below the calendar with three compact KPIs: Time, Distance, Ascent.\n    - Time: sum of plannedDurationSec formatted as h:mm (or hh:mm) using utils/formatting.\n    - Distance: sum of plannedDistanceKm where available; otherwise use estimate. Label simply \"Distance\"; add tooltip: \"Uses planned distance when set; otherwise estimate\". Optionally show a secondary line or tooltip breakdown using distancePlannedOnlyKm and distanceEstimatedOnlyKm.\n    - Ascent: sum of plannedAscentM. If many sessions lack ascent, display the sum of known ascent and do not estimate.\n  - Recompute whenever the week or sessions change (creation, edit, delete). Use memoization in PlannerService to avoid UI lag on refresh.\n\nFormatting and rounding\n- Cards: show km with 1 decimal; details page show km with 1–2 decimals; totals show 1 decimal.\n- Use utils/formatting.py from Task 11 for FR locale conventions (decimal comma, non-breaking spaces). Fallback gracefully if OS locale unavailable (as in Task 11 tests).\n\nPerformance and resilience\n- Avoid blocking UI: compute on background thread or precompute totals on data load. Memoize weekly_totals by (athleteId, weekStartISO, dataVersion).\n- If thresholds and recent easy pace are both missing, show \"Est: —\" and exclude from estimated distance contributions (only planned distances will sum). Tooltip: \"Missing thresholds/easy pace; cannot estimate.\" \n\nAccessiblity and UX notes\n- Provide aria-labels for badges and totals. Ensure contrasts on badges meet WCAG AA.\n\nNo storage/schema changes\n- Do not write estimated distances to any CSV. The estimates are strictly for display.\n",
        "testStrategy": "Unit tests (PlannerService)\n1) Fundamental estimate\n   - thresholds.fundamental = 5:30/km (330 s/km). plannedDurationSec=3600, no plannedDistanceKm.\n   - estimate_distance_km returns ~10.91 (assert within ±0.01); rounding to 1 decimal for UI should be 10.9.\n2) Long run with planned distance present\n   - plannedDistanceKm=20.0 and plannedDurationSec=7200, thresholds present.\n   - estimate_distance_km returns an estimate (≈ duration/pace) but UI logic will show planned distance as primary; ensure weekly_totals.distanceKm uses 20.0 (planned) for this session.\n3) Intervals (auto steps)\n   - steps with auto durations totaling 1800 s; no session-level duration; fundamental pace 6:00/km.\n   - estimate_distance_km ≈ 5.0 km.\n4) Intervals with 'lap' only steps\n   - no durations, no plannedDistanceKm; fundamental pace present but no usable duration.\n   - estimate_distance_km returns None.\n5) Fallback to recent easy pace\n   - No thresholds.fundamental, recent_easy_pace_s_per_km=360.\n   - Fundamental 30 min => estimate 5.0 km.\n6) Weekly totals aggregation\n   - Build a week with: (a) fundamental 60 min (no distance), (b) long run 20 km, (c) intervals 30 min (no distance), (d) session with ascentM set.\n   - Verify timeSec equals sum of known durations; distanceKm equals planned when set else estimates; ascentM sums only known ascent.\n   - Verify distancePlannedOnlyKm and distanceEstimatedOnlyKm breakdowns are correct.\n\nUI tests (manual or integration)\n1) Week grid width\n   - On a desktop viewport (>=1440px), grid expands to wider layout; no wrapping of icon actions. Below 1024px, grid remains usable with horizontal scroll if needed.\n2) Cards show estimates\n   - With a session lacking plannedDistanceKm, card shows \"Est: X.X km\".\n   - With a session having plannedDistanceKm and a different estimate, card shows both Dist and Est (Est omitted if difference <0.1 km).\n3) Session details\n   - Details page displays \"Estimated distance\"; matches PlannerService output.\n4) Weekly totals\n   - Totals row shows Time (formatted), Distance (sum using planned then estimated), and Ascent.\n   - Editing a session (change duration or set distance) updates totals immediately after save.\n5) Locale formatting\n   - Verify decimal comma in km values and correct time formatting using utils/formatting.py.\n\nNon-regression\n- Create/edit/delete sessions still modify CSV exactly as before (no new fields written). Confirm file diffs show no schema changes.\n- Performance: recomputing totals on a week with 50–100 sessions completes without noticeable UI lag (<100 ms) on a typical dev machine.\n",
        "status": "done",
        "dependencies": [
          12
        ],
        "priority": "medium",
        "subtasks": []
      },
      {
        "id": 14,
        "title": "Interval editor: Loops mode with repeats, between-loop recovery, ascend/descent targets, and updated estimation",
        "description": "Refactor the interval editor and step schema to add a Loops mode supporting per-loop actions (run/recovery with intensity), loop repeats with an optional between-loop recovery step, and optional ascend/descent targets per action. Keep full backward compatibility with the existing repeats structure and update distance/time/ascent estimation to handle loops.",
        "details": "Scope and goals\n- Add a Loops mode to the interval editor that lets users define a sequence of actions (e.g., Run, Recovery) that is repeated N times (loop repeats), with an optional between-loop recovery step inserted between loops.\n- Extend step metadata to allow optional ascendTargetM and descendTargetM per action.\n- Backward compatible with existing repeats structure: no breaking changes to stored JSON; existing sessions load and behave unchanged. Existing repeat groups remain valid.\n- Update PlannerService estimation logic to correctly compute time, distance, and ascent for loops, including between-loop recovery and per-action ascend/desc targets.\n- Maintain current UI patterns introduced in Task 12 and estimation centralization from Task 13.\n\nData model and schema changes (non-breaking extensions)\n- Keep current INTERVAL_SIMPLE steps JSON shape and RepeatGroup concept. Extend it minimally to support loops semantics:\n  - Step (existing): { stepType: 'WORK'|'RECOVERY', endMode: 'auto'|'lap', durationSec? number, distanceKm? number, target?: { type: 'pace'|'hr'|'sensation', label: string, value?: number|string } }\n  - New optional fields on Step: ascendTargetM?: number, descendTargetM?: number\n  - RepeatGroup (existing): { repeat: number, steps: Step[] }\n  - New optional field on RepeatGroup: betweenRepeatStep?: Step (inserted between repeats, but not after the last repeat)\n- Loops mode is expressed by using a RepeatGroup with steps representing the per-loop action sequence and optionally betweenRepeatStep. This reuses the existing repeats structure, satisfying backward compatibility.\n- No change to top-level session schema or CSV columns; all extensions stay within the steps JSON payload. Ensure default behavior for missing new fields remains identical to current.\n\nEditor UX/behavior\n- Add a Mode toggle at the top of the interval editor: Simple vs Loops.\n  - Simple mode: current behavior (unchanged), supports a flat list of steps and optional simple repeats as today.\n  - Loops mode: editor shows a list of Loop Actions (the sequence executed within a loop):\n    - Actions can be added/removed/reordered. Each action has: actionType ('RUN' or 'RECOVERY'), endMode ('auto' or 'lap'), durationSec or distanceKm (at least one required; rules below), target selector (pace/hr/sensation) with label, optional ascendTargetM and descendTargetM.\n    - Loop repeats: integer >= 1.\n    - Between-loop recovery: optional Step editor with same fields as actions. Inserted between loop iterations but not after the last iteration.\n- Validation rules:\n  - Each action must have either durationSec or distanceKm. Allow both (if both provided, estimation prefers the one aligned with endMode: if endMode='auto' and durationSec set, use duration; if distanceKm set and no duration, estimate time via target pace; see Estimation rules). Show clear inline validation messages.\n  - ascendTargetM and descendTargetM must be >= 0 and integers; optional.\n  - Loop repeats must be 1–999.\n  - Total steps count preview must reflect (repeats × actions) plus inserted between-loop steps.\n- Live preview and summary:\n  - Show expanded preview of the resulting flattened sequence (without actually writing a flattened structure), including count of total steps.\n  - Show estimated total time, distance, and ascent using PlannerService.\n\nEstimation (PlannerService) updates\n- Extend PlannerService to support loops-aware estimation, while keeping the existing public interface and centralization from Task 13.\n- Parsing logic:\n  - Detect RepeatGroup with betweenRepeatStep. Treat it as Loops if repeat >= 1 and steps length >= 1.\n  - Expand virtually for estimation only (do not persist expansion): total over (repeat times) of action sequence, inserting betweenRepeatStep between iterations (i < repeat-1).\n- Per-action estimation:\n  - If durationSec is provided:\n    - time = durationSec; distance estimation depends on target pace if available; if pace target has a parsable pace value (e.g., 4:30/km), distance = time / pace_sec_per_km. If no pace target, use thresholds defaults already used in Task 13 for the given intensity/target type; fallback to session default pace if configured.\n  - If distanceKm is provided and pace is known/derivable: time = distanceKm × pace_sec_per_km.\n  - If both durationSec and distanceKm are provided: prefer durationSec for time and compute distance from pace if present; if pace unknown, trust provided distanceKm.\n  - ascendTargetM and descendTargetM add to ascent/desc totals directly and are multiplied appropriately by repeats. If both are provided, add both to totals; ascent totals drive weekly ascent metrics used by Task 13 UI.\n- Aggregation:\n  - Sum timeSec, distanceKm, ascentM, and descentM across the expanded logical sequence including between-loop recoveries.\n  - Ensure rounding is consistent with Task 13 (e.g., show 1 decimal km in UI, but keep internal precision).\n\nPersistence and compatibility\n- Loader must accept sessions without ascend/desc fields and without betweenRepeatStep (no behavior change).\n- Saver must only include betweenRepeatStep when Loops mode is used; otherwise keep current structure.\n- Do not change CSV schemas or add files. Keep steps JSON compact and version-less; rely on presence of betweenRepeatStep and/or UI mode flag to toggle editor behavior.\n\nOther impacts and non-goals\n- Garmin TCX export (Task 10) is out of scope here. Ensure exporter calls do not break when encountering betweenRepeatStep or ascend/desc fields; they should be ignored or flattened by a later task.\n- Analytics (Task 9) is out of scope. Preserve stepType semantics (WORK vs RECOVERY) so future classification remains correct.\n- No device-specific features beyond existing endMode handling.\n\nImplementation notes\n- Types: define Step, RepeatGroup, and helper guards in a shared module (e.g., domain/interval_types.py or ts types if frontend). Include ascendTargetM/descendTargetM and betweenRepeatStep optional fields.\n- Editor: implement a small component for Between-loop Recovery that reuses the action editor with a distinct label. Disable reorder and delete for this slot, provide a toggle to enable/disable it.\n- PlannerService: add estimate_interval_loops(group, ctx) and wire it into the existing estimate_session() path. Keep all callers unchanged.\n- Validation utilities: add helpers to parse pace labels (mm:ss/km) robustly and to compute default pace fallbacks consistent with Task 13 thresholds.\n- Preview: implement a generator to produce a flattened list for display only; do not persist flattened data.\n",
        "testStrategy": "Unit tests (PlannerService)\n1) Loops with duration-based run and recovery, plus between-loop recovery\n   - Actions: [RUN 3:00 @ 4:30/km, REC 1:00 easy], repeats=5, betweenLoop REC 2:00 easy.\n   - Expect timeSec = 5*(3*60 + 1*60) + 4*2*60 = 15*60 + 5*60 + 8*60 = 28*60 = 1680 sec.\n   - Distance: RUN segments only use pace: 5 * (180 sec / 270 sec/km) = 3.333... km; REC segments distance derived from easy pace fallback (e.g., thresholds.fundamental if configured). Assert within ±0.01 with a fixed thresholds fixture.\n   - Ascent: if RUN ascendTargetM=20, REC ascendTargetM=0, betweenLoop ascendTargetM=5, expect ascentM = 5*20 + 4*5 = 120 m.\n2) Loops with distance-based run and known pace\n   - RUN 1.0 km @ 4:00/km, REC 0.5 km @ 6:00/km, repeats=3, no between-loop.\n   - timeSec = 3*(240 + 180) = 1260 sec; distanceKm = 3*(1.0 + 0.5) = 4.5 km.\n3) Mixed provided duration and distance\n   - RUN duration 120 sec with no pace target, REC distance 0.2 km with easy pace default, repeats=4, betweenLoop REC 60 sec.\n   - Verify time and distance computed using default pace fallback rules; assert values against precomputed expectations.\n4) Backward compatibility: existing Simple sessions\n   - Load a legacy session with a RepeatGroup lacking betweenRepeatStep and without ascend/desc fields; estimate matches previous implementation within tolerance. Ensure serialization round-trips unchanged.\n5) Edge cases\n   - repeats=1: betweenRepeatStep must not be counted. Zero ascend/desc values do not affect totals.\n   - endMode='lap': estimation still uses provided duration/distance/pace; presence of lap end should not crash.\n\nUnit tests (schema/serialization)\n- Steps with ascendTargetM/descendTargetM and betweenRepeatStep serialize and deserialize correctly. Unknown fields are ignored by older parsers in tests using compatibility guards.\n\nUI tests (manual)\n- In the interval editor, toggle Loops mode, add two actions, set repeats, enable between-loop recovery, and enter ascend/desc values. Verify live preview count, estimated totals (time/distance/ascent), and validation messages.\n- Switch between Simple and Loops modes; confirm no data loss when switching back and forth within the session editor before save.\n- Open a legacy interval session; verify it defaults to Simple mode with identical preview and estimates as before.\n\nRegression\n- Weekly totals bar (Task 13) reflects ascent/time/distance for a week containing loop-based sessions; totals match PlannerService estimates.\n",
        "status": "done",
        "dependencies": [
          13
        ],
        "priority": "high",
        "subtasks": []
      },
      {
        "id": 15,
        "title": "Automated tests for Planner UI enhancements",
        "description": "Add unit tests covering the Planner UI and services delivered in tasks 12, 13, and 14.",
        "details": "Implement unit tests that validate:\n- Rendering helpers for Planner session cards, including icon actions, compact badges, and empty-state placeholders.\n- PlannerService weekly totals, estimated distance calculations for sessions, and card/detail displays introduced in Task 13.\n- Interval editor loops mode estimation logic, including loop repeats, between-loop recovery, and ascent/descent targets, preserving backward compatibility with legacy step schemas.\nCoordinate with existing modules in pages/Planner.py, PlannerService, and interval estimation utilities. Tests should use pytest and focus on business logic functions (not Streamlit UI widgets) to ensure regression protection for the Planner experience.",
        "testStrategy": "Add pytest unit modules targeting planner-related services/utilities. Ensure tests assert expected collections/dicts given representative input CSV rows, including edge cases for loops mode. Run pytest to confirm coverage.",
        "status": "done",
        "dependencies": [],
        "priority": "medium",
        "subtasks": [
          {
            "id": 1,
            "title": "Pytest scaffolding and shared fixtures for Planner tests",
            "description": "Create a pytest testing scaffold and reusable fixtures covering thresholds, representative planned session rows, and interval steps JSON (legacy and loops mode). Ensure tests can run without Streamlit by targeting pure functions only.",
            "dependencies": [],
            "details": "Implementation steps:\n- Add pytest config\n  - Create pytest.ini with testpaths=tests and addopts such as -q. Optionally set markers like [planner].\n- Directory layout\n  - tests/planner/ for planner-related unit tests\n  - tests/fixtures/ for sample JSON and builders\n- Shared fixtures in tests/planner/conftest.py\n  - thresholds fixture: returns a simple object/dict used by PlannerService with at least fundamental pace (e.g., fundamental_pace_sec_per_km=330), threshold60 and threshold30 pace values if needed by estimators, and fallback easy pace.\n  - session_row factory: returns a dict mimicking planned_sessions.csv rows with keys like id, athleteId, date (YYYY-MM-DD), type, plannedDurationSec, plannedDistanceKm (optional), targetType, targetLabel, stepEndMode, stepsJson (JSON string). Keep schema stable (no new columns).\n  - interval_steps_legacy fixture: returns a JSON-serializable list of steps for a simple interval workout using the legacy structure (no loops metadata) with explicit distances and recoveries.\n  - interval_steps_loops fixture: returns a JSON-serializable object using loops mode, including fields for loop repeats, between-loop recovery, and nested step repeats with explicit distances/time.\n  - week_sessions fixture: builds a list of three representative sessions for a Mon–Sun week: FUNDAMENTAL_ENDURANCE with duration only; LONG_RUN with plannedDistanceKm set; INTERVAL_SIMPLE using interval_steps_loops. Include ascent/descent targets on interval steps where applicable.\n- Utilities\n  - Helper to JSON-dump steps fixtures into stepsJson so tests can feed the exact string to service functions.\n  - If any module relies on timezone or locale, set deterministic env (e.g., TZ=UTC) within tests via monkeypatch or os.environ.\n- Do not import or instantiate Streamlit; keep fixtures pure data.",
            "status": "done",
            "testStrategy": "Add a smoke test in tests/planner/test_fixtures_smoke.py that asserts: thresholds fields exist; session_row factory yields dicts with expected keys and JSON-serializable stepsJson; interval_steps_legacy vs interval_steps_loops produce different shapes but both valid JSON and non-empty. Run pytest to ensure setup is correct."
          },
          {
            "id": 2,
            "title": "Interval estimation utilities: loops mode, recovery, and ascent/descent compatibility tests",
            "description": "Write unit tests for the interval estimation utilities covering loops mode semantics, between-loop recovery handling, ascent/descent aggregation, and backward compatibility with legacy step schemas.",
            "dependencies": [
              "15.1"
            ],
            "details": "Implementation steps:\n- Identify the pure estimation entry points (e.g., interval_estimation.estimate_session_metrics(steps, thresholds) or similar). If the logic currently lives inside UI code, extract a pure function into services/interval_estimation.py or planner/interval_utils.py and import it in pages/Planner.py to preserve behavior.\n- Test cases (use interval_steps_* fixtures):\n  1) Loops mode aggregation\n     - Build loops: 2 loops; each loop has 4 repeats of 400 m work with 200 m recovery (distance-based), plus between-loop recovery of 120 s (time-based). Assert:\n       - totalDistanceMeters == 2 * 4 * (400 + 200) = 4800 m;\n       - totalTimeSec includes all time-based recoveries plus work durations (if pace/time-based). If work/recovery are distance-based without pace, ensure estimator either leaves time as None or computes from thresholds consistently; assert logical consistency (non-negative and greater than time-based only parts).\n  2) Between-loop recovery semantics\n     - Ensure only the number of gaps between loops contribute (loops-1). E.g., for 2 loops with 120 s between-loop recovery, total extra recovery time = 120 s. Assert the estimator does not multiply between-loop recovery by number of repeats within loops.\n  3) Ascent/descent targets aggregation\n     - Include ascentTargetMeters and descentTargetMeters per loop (e.g., 150 m each per loop). With 2 loops, assert ascentMeters == 300 and descentMeters == 300 in the returned metrics.\n  4) Backward compatibility with legacy steps\n     - Construct a legacy steps list (no loops metadata) replicating the same workout totals as the loops structure. Assert estimate metrics (distance, time if computable, ascent/descent) match within tolerances.\n  5) Edge conditions\n     - Missing or zero loop repeats: if repeats is missing, assert default behavior equals 1 loop; if repeats==0, assert zero contribution for that section and no crash.\n- Use approx with tolerances (e.g., 1e-2 for km, 1e-6 for meters) when floating conversions are involved.",
            "status": "done",
            "testStrategy": "Implement tests in tests/planner/test_interval_estimation.py using the fixtures. Parametrize over loops/legacy inputs to assert metric equivalence. Add targeted tests for between-loop recovery and ascent/descent aggregation. Ensure no Streamlit imports; only pure functions."
          },
          {
            "id": 3,
            "title": "PlannerService session estimation: distance for cards/details and overrides",
            "description": "Create unit tests for PlannerService session-level estimations, validating estimated distance calculations used on session cards and details, and honoring plannedDistance overrides when provided.",
            "dependencies": [
              "15.1",
              "15.2"
            ],
            "details": "Implementation steps:\n- Identify the service API (e.g., PlannerService.estimate_distance_km(session_row, thresholds) and any wrapper that returns a session display model used by cards/details). If not present, factor a pure helper inside PlannerService that accepts a plain dict session and thresholds and returns estimates without side effects.\n- Fundamental endurance estimate (from Task 13 spec)\n  - thresholds.fundamental = 330 s/km (5:30/km), plannedDurationSec=3600, plannedDistanceKm missing.\n  - Assert estimate_distance_km ≈ 3600 / 330 = 10.909... km (±0.01). If a UI-rounding helper exists, assert it rounds/display-formats to 10.9.\n- Long run with planned distance present\n  - Provide plannedDistanceKm=20.0 and duration. Assert service prefers the explicit plannedDistanceKm for card/details display and does not recompute or override.\n- Interval session integration\n  - Use the interval_steps_loops fixture to build an INTERVAL_SIMPLE session lacking plannedDistanceKm.\n  - Ensure PlannerService invokes the interval estimation utility (verified either by black-box equality with Subtask 2 totals or by monkeypatching/spying the utility function) and converts total meters to km for display.\n- Missing data fallbacks\n  - If neither plannedDistanceKm nor estimable pace/steps are present, assert the estimate returns None (or a sentinel) and that any display model omits the distance badge gracefully.\n- Thresholds provider injection\n  - If PlannerService normally resolves thresholds from athlete context, provide a way to inject thresholds via function argument or monkeypatching for determinism in tests.",
            "status": "done",
            "testStrategy": "Add tests to tests/planner/test_planner_service_estimates.py. Use approx for numeric checks. Include a spy/monkeypatch to assert interval estimator is called for interval sessions. Verify rounding intended for UI is applied only at the presentation boundary, keeping raw estimates precise."
          },
          {
            "id": 4,
            "title": "Weekly totals aggregation in PlannerService",
            "description": "Implement tests that verify weekly totals (time, distance, ascent) under the grid are correctly computed from session list using estimates where needed, without mutating storage or CSV schemas.",
            "dependencies": [
              "15.3"
            ],
            "details": "Implementation steps:\n- Locate or add a pure function in PlannerService such as compute_weekly_totals(sessions: list[dict], thresholds) -> dict(timeSec, distanceKm, ascentMeters) that:\n  - Sums plannedDurationSec for timeSec.\n  - Sums plannedDistanceKm if present; otherwise adds estimate_distance_km(session) where estimable; skips None.\n  - Sums ascentMeters by preferring explicit session ascent if available; otherwise adds estimated ascent from interval estimation for interval sessions; else 0.\n- Use the week_sessions fixture (Fundamental w/o distance, Long run with distance, Interval with loops and ascent/descent targets) to compute totals.\n- Expected assertions:\n  - timeSec equals sum of plannedDurationSec across sessions (ensure integer sum, not rounded display values).\n  - distanceKm equals sum of: long run plannedDistanceKm + fundamental estimated km from thresholds + interval estimated km (from Subtask 3 logic), within ±0.01.\n  - ascentMeters equals sum of interval ascent estimates (and any explicit ascent fields if present on other types), exact integer sum.\n- Edge cases:\n  - Empty week -> all zeros.\n  - Sessions outside the target week are excluded if the service supports week filtering; otherwise filter in the test prior to calling totals.\n  - Sessions with invalid/missing duration/distance should not crash and should be skipped in sums appropriately.",
            "status": "done",
            "testStrategy": "Create tests in tests/planner/test_planner_service_totals.py. Build deterministic expected totals from fixture data and previously validated estimate functions. Use approx for distanceKm and exact equality for timeSec/ascentMeters. Include a test that ensures no CSV writes or schema changes occur during computation (e.g., by asserting input dicts unchanged before/after)."
          },
          {
            "id": 5,
            "title": "Rendering helpers for Planner session cards and empty-state placeholder",
            "description": "Add unit tests for pure rendering helpers that map session/service data to card/detail display models, including icon actions, compact badges, end-mode and target badges, and the empty-state placeholder. Avoid testing Streamlit widgets directly.",
            "dependencies": [
              "15.3"
            ],
            "details": "Implementation steps:\n- Identify pure helper(s) used by pages/Planner.py to prepare card/detail data. If the logic is inline with Streamlit, extract to a new pure module (e.g., planner/card_helpers.py) exporting:\n  - build_card_view_model(session: dict, estimates: dict|None, routes: dict) -> dict containing fields like title, subtitle, badges (list of label/value), and actions (list of {icon, ariaLabel, href}).\n  - build_details_view_model(session: dict, estimates: dict|None) -> dict for the details page sections.\n  - build_empty_week_placeholder(week_range: tuple[date,date]) -> dict containing message text and CTA metadata (e.g., {icon, label, href}).\n- Card model expectations:\n  - Actions include exactly the icon-only set: edit, delete, view, mapped to routes (no Streamlit st.button usage in helpers). Assert icon identifiers and that hrefs embed the session id.\n  - Badges include: duration, distance (planned or estimated, rounded to 1 decimal), targetType/targetLabel (ensure new naming like 'Threshold 60'/'Threshold 30' pass through as-is), and end mode when present.\n  - For sessions with no distance and non-estimable, omit the distance badge (do not show zero) and ensure no crash.\n- Empty-state placeholder expectations:\n  - Returned dict includes a descriptive message and a CTA to create the first session or apply a template.\n  - Ensure no Streamlit imports.\n- Wire-up note: pages/Planner.py should call these helpers; tests only target the helper outputs, not the Streamlit rendering.",
            "status": "done",
            "testStrategy": "Create tests in tests/planner/test_card_helpers.py. Use sample sessions from fixtures and a simple routes dict (e.g., {'edit': '/planner/edit/{id}', 'delete': '/planner/delete/{id}', 'view': '/planner/session/{id}'}). Assert that returned dicts contain the expected icons, badges (with correctly rounded km), and that the empty-state model is produced when an empty session list is passed to the consumer. Validate that helper modules import no streamlit."
          }
        ]
      },
      {
        "id": 16,
        "title": "Unit tests for Planner enhancements (Tasks 12-14)",
        "description": "Create comprehensive unit tests covering the Planner UI and service changes delivered in tasks 12, 13, and 14, including session cards, estimated kilometers, weekly totals logic, and interval loops mode.",
        "details": "Add tests targeting:\n- PlannerService estimation helpers introduced for cards/details and loops handling\n- UI formatting utilities (format_duration, summarize_targets) to ensure badge text and estimations match expectations\n- Repo caching invalidation to guarantee fresh data after create/update/delete operations\nEnsure tests isolate storage using tmp_path fixtures and cover edge cases introduced in the enhancements.",
        "testStrategy": "pytest -k planner or full test suite",
        "status": "done",
        "dependencies": [
          12,
          13,
          14
        ],
        "priority": "medium",
        "subtasks": []
      }
    ],
    "metadata": {
      "created": "2025-10-06T19:00:14.797Z",
      "updated": "2025-10-07T13:42:28.601Z",
      "description": "Tasks for master context"
    }
  }
}